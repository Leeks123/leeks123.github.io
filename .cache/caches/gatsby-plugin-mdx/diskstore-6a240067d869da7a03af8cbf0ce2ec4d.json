{"expireTime":9007200852998739000,"key":"gatsby-plugin-mdx-entire-payload-e31c8c1ec503fe026085b7b092333bca-","val":{"mdast":{"type":"root","children":[{"type":"heading","depth":3,"children":[{"type":"text","value":"KNN","position":{"start":{"line":2,"column":5,"offset":5},"end":{"line":2,"column":8,"offset":8},"indent":[]}}],"position":{"start":{"line":2,"column":1,"offset":1},"end":{"line":2,"column":8,"offset":8},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"지도학습, 분류 알고리즘","position":{"start":{"line":4,"column":3,"offset":12},"end":{"line":4,"column":16,"offset":25},"indent":[]}}],"position":{"start":{"line":4,"column":3,"offset":12},"end":{"line":4,"column":16,"offset":25},"indent":[]}}],"position":{"start":{"line":4,"column":1,"offset":10},"end":{"line":4,"column":16,"offset":25},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"주어진 데이터로부터 거리가 가까운 k개의 다른 데이터들의 라벨 중 가장 많은 비율을 차지하는 라벨을 참조하여 분류하는 알고리즘","position":{"start":{"line":5,"column":3,"offset":28},"end":{"line":5,"column":73,"offset":98},"indent":[]}}],"position":{"start":{"line":5,"column":3,"offset":28},"end":{"line":5,"column":73,"offset":98},"indent":[]}}],"position":{"start":{"line":5,"column":1,"offset":26},"end":{"line":5,"column":73,"offset":98},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"사례 기반 알고리즘의 한 종류로 데이터 양이 많아지면 속도가 느려질 수 있음","position":{"start":{"line":6,"column":3,"offset":101},"end":{"line":6,"column":45,"offset":143},"indent":[]}}],"position":{"start":{"line":6,"column":3,"offset":101},"end":{"line":6,"column":45,"offset":143},"indent":[]}}],"position":{"start":{"line":6,"column":1,"offset":99},"end":{"line":6,"column":45,"offset":143},"indent":[]}}],"position":{"start":{"line":4,"column":1,"offset":10},"end":{"line":6,"column":45,"offset":143},"indent":[1,1]}},{"type":"heading","depth":4,"children":[{"type":"text","value":"K 개수 최적화 문제","position":{"start":{"line":8,"column":6,"offset":150},"end":{"line":8,"column":17,"offset":161},"indent":[]}}],"position":{"start":{"line":8,"column":1,"offset":145},"end":{"line":8,"column":17,"offset":161},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"k값이 클 때 전체적인 노이즈를 줄일 수 있지만 중요한 패턴을 무시할 가능성","position":{"start":{"line":10,"column":3,"offset":165},"end":{"line":10,"column":45,"offset":207},"indent":[]}}],"position":{"start":{"line":10,"column":3,"offset":165},"end":{"line":10,"column":45,"offset":207},"indent":[]}}],"position":{"start":{"line":10,"column":1,"offset":163},"end":{"line":10,"column":45,"offset":207},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"최적의 K값을 찾기 위해 K-fold Cross-validation 방법을 활용","position":{"start":{"line":11,"column":3,"offset":210},"end":{"line":11,"column":47,"offset":254},"indent":[]}}],"position":{"start":{"line":11,"column":3,"offset":210},"end":{"line":11,"column":47,"offset":254},"indent":[]}}],"position":{"start":{"line":11,"column":1,"offset":208},"end":{"line":11,"column":47,"offset":254},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"k=1일 때 ","position":{"start":{"line":12,"column":3,"offset":257},"end":{"line":12,"column":10,"offset":264},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"over-fitting","position":{"start":{"line":12,"column":12,"offset":266},"end":{"line":12,"column":24,"offset":278},"indent":[]}}],"position":{"start":{"line":12,"column":10,"offset":264},"end":{"line":12,"column":26,"offset":280},"indent":[]}},{"type":"text","value":" 될 수 있음","position":{"start":{"line":12,"column":26,"offset":280},"end":{"line":12,"column":33,"offset":287},"indent":[]}}],"position":{"start":{"line":12,"column":3,"offset":257},"end":{"line":12,"column":33,"offset":287},"indent":[]}}],"position":{"start":{"line":12,"column":1,"offset":255},"end":{"line":12,"column":33,"offset":287},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"k값이 너무 클 때 새로운 데이터의 라벨은 항상 전체 데이터의 대다수를 차지하는 라벨로 분류하는 ","position":{"start":{"line":13,"column":3,"offset":290},"end":{"line":13,"column":57,"offset":344},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"under fitting","position":{"start":{"line":13,"column":59,"offset":346},"end":{"line":13,"column":72,"offset":359},"indent":[]}}],"position":{"start":{"line":13,"column":57,"offset":344},"end":{"line":13,"column":74,"offset":361},"indent":[]}},{"type":"text","value":" 문제 발생","position":{"start":{"line":13,"column":74,"offset":361},"end":{"line":13,"column":80,"offset":367},"indent":[]}}],"position":{"start":{"line":13,"column":3,"offset":290},"end":{"line":13,"column":80,"offset":367},"indent":[]}}],"position":{"start":{"line":13,"column":1,"offset":288},"end":{"line":13,"column":80,"offset":367},"indent":[]}}],"position":{"start":{"line":10,"column":1,"offset":163},"end":{"line":13,"column":80,"offset":367},"indent":[1,1,1]}},{"type":"thematicBreak","position":{"start":{"line":15,"column":1,"offset":369},"end":{"line":15,"column":4,"offset":372},"indent":[]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"KNN 실습","position":{"start":{"line":16,"column":5,"offset":377},"end":{"line":16,"column":11,"offset":383},"indent":[]}}],"position":{"start":{"line":16,"column":1,"offset":373},"end":{"line":16,"column":11,"offset":383},"indent":[]}},{"type":"heading","depth":4,"children":[{"type":"text","value":"패키지 , 데이터 로드","position":{"start":{"line":18,"column":6,"offset":390},"end":{"line":18,"column":18,"offset":402},"indent":[]}}],"position":{"start":{"line":18,"column":1,"offset":385},"end":{"line":18,"column":18,"offset":402},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.preprocessing import normalize","position":{"start":{"line":21,"column":1,"offset":405},"end":{"line":32,"column":4,"offset":750},"indent":[1,1,1,1,1,1,1,1,1,1,1]}},{"type":"code","lang":"python","meta":null,"value":"breast_cancer = load_breast_cancer()\nX = breast_cancer.data\ny = breast_cancer.target\n\ndf = pd.DataFrame(X,columns = breast_cancer.feature_names)","position":{"start":{"line":35,"column":1,"offset":753},"end":{"line":41,"column":4,"offset":911},"indent":[1,1,1,1,1,1]}},{"type":"heading","depth":4,"children":[{"type":"text","value":"데이터 셋 분리","position":{"start":{"line":44,"column":6,"offset":919},"end":{"line":44,"column":14,"offset":927},"indent":[]}}],"position":{"start":{"line":44,"column":1,"offset":914},"end":{"line":44,"column":14,"offset":927},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33, random_state = 42)","position":{"start":{"line":47,"column":1,"offset":930},"end":{"line":49,"column":4,"offset":1034},"indent":[1,1]}},{"type":"heading","depth":4,"children":[{"type":"text","value":"모델 학습 및 정확도 측정","position":{"start":{"line":51,"column":6,"offset":1041},"end":{"line":51,"column":20,"offset":1055},"indent":[]}}],"position":{"start":{"line":51,"column":1,"offset":1036},"end":{"line":51,"column":20,"offset":1055},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"estimator = KNeighborsClassifier(n_neighbors=5, weights = 'distance')\n\nestimator.fit(X_train,y_train)\n\nlabel_predict = estimator.predict(X_test)\n\nprint(\"The accuracy score of classification: %.9f\"%accuracy_score(y_test,label_predict))","position":{"start":{"line":54,"column":1,"offset":1058},"end":{"line":62,"column":4,"offset":1306},"indent":[1,1,1,1,1,1,1,1]}},{"type":"code","lang":null,"meta":null,"value":"The accuracy score of classification: 0.941489362","position":{"start":{"line":64,"column":1,"offset":1308},"end":{"line":64,"column":54,"offset":1361},"indent":[]}},{"type":"heading","depth":4,"children":[{"type":"text","value":"Cross Validation방법을 사용하여 최적의 k값을 찾기","position":{"start":{"line":67,"column":6,"offset":1369},"end":{"line":67,"column":41,"offset":1404},"indent":[]}}],"position":{"start":{"line":67,"column":1,"offset":1364},"end":{"line":67,"column":41,"offset":1404},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"myList = list(range(1,100))\nneighbors = [ x for x in myList if x%2!=0]\nprint(\"k의 후보값들 추출\",neighbors)\ncv_scores = []","position":{"start":{"line":70,"column":1,"offset":1407},"end":{"line":75,"column":4,"offset":1536},"indent":[1,1,1,1,1]}},{"type":"code","lang":null,"meta":null,"value":"k의 후보값들 추출 [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 69, 71, 73, 75, 77, 79, 81, 83, 85, 87, 89, 91, 93, 95, 97, 99]","position":{"start":{"line":77,"column":1,"offset":1538},"end":{"line":77,"column":211,"offset":1748},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"for k in neighbors:\n    print(\"< k = %d >\"%k)\n    estimator = KNeighborsClassifier(n_neighbors=k)\n    scores = cross_val_score(estimator, X_train, y_train, cv=10,scoring=\"accuracy\")\n    print(\"The scores of classification are \\n\"+str(scores))\n    cv_scores.append(scores.mean())\n    print(\"The average score of score is %.9f \\n\"%scores.mean())","position":{"start":{"line":81,"column":1,"offset":1752},"end":{"line":89,"column":4,"offset":2109},"indent":[1,1,1,1,1,1,1,1]}},{"type":"code","lang":null,"meta":null,"value":"< k = 1 >\nThe scores of classification are \n[0.97435897 0.84210526 0.92105263 0.97368421 0.81578947 0.89473684\n 0.89473684 0.89473684 0.89473684 0.84210526]\nThe average score of score is 0.894804318 \n\n< k = 3 >\nThe scores of classification are \n[0.94871795 0.86842105 0.89473684 0.94736842 0.94736842 0.89473684\n 0.86842105 0.89473684 0.94736842 0.81578947]\nThe average score of score is 0.902766532 \n\n< k = 5 >\nThe scores of classification are \n[0.94871795 0.86842105 0.89473684 0.94736842 0.94736842 0.92105263\n 0.94736842 0.86842105 0.92105263 0.81578947]\nThe average score of score is 0.908029690 \n\n...","position":{"start":{"line":91,"column":1,"offset":2111},"end":{"line":109,"column":8,"offset":2789},"indent":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]}},{"type":"code","lang":"python","meta":null,"value":"MSE = [1 - x for x in cv_scores]\n\nplt.plot(neighbors, MSE)\nplt.xlabel(\"Number of Neighbors K\")\nplt.ylabel(\"Misclassification Error\")\nplt.show()\n\nmin_MSE = min(MSE)\nindex_of_min_MSE = MSE.index(min_MSE)\noptimal_k = neighbors[index_of_min_MSE]\nprint(\"The optimal number of neighbors i is %d\"%optimal_k)","position":{"start":{"line":112,"column":1,"offset":2792},"end":{"line":124,"column":4,"offset":3106},"indent":[1,1,1,1,1,1,1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"image","title":null,"url":"./ch10_25_0.png","alt":"png","position":{"start":{"line":127,"column":1,"offset":3109},"end":{"line":127,"column":24,"offset":3132},"indent":[]}}],"position":{"start":{"line":127,"column":1,"offset":3109},"end":{"line":127,"column":24,"offset":3132},"indent":[]}},{"type":"code","lang":null,"meta":null,"value":"The optimal number of neighbors i is 13","position":{"start":{"line":130,"column":1,"offset":3135},"end":{"line":130,"column":44,"offset":3178},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"estimator = KNeighborsClassifier(n_neighbors =13)\nestimator.fit(X_train,y_train)\n\nlabel_predict = estimator.predict(X_test)\n\nprint(\"accuracy: %.9f\"%accuracy_score(y_test, label_predict))","position":{"start":{"line":134,"column":1,"offset":3182},"end":{"line":141,"column":4,"offset":3382},"indent":[1,1,1,1,1,1,1]}},{"type":"code","lang":null,"meta":null,"value":"accuracy: 0.962765957","position":{"start":{"line":143,"column":1,"offset":3384},"end":{"line":143,"column":26,"offset":3409},"indent":[]}},{"type":"export","value":"export const _frontmatter = {\"title\":\"<파이썬을 이용한 빅데이터 분석> ch10 KNN\",\"date\":\"2020-08-24T00:00:00.000Z\",\"tags\":[\"Python\",\"BigData\",\"MachineLearning\"]}","position":{"start":{"line":147,"column":1,"offset":3413},"end":{"line":147,"column":148,"offset":3560},"indent":[]}}],"position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":147,"column":148,"offset":3560}}},"scopeImports":["import * as React from 'react'"],"scopeIdentifiers":["React"],"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"<파이썬을 이용한 빅데이터 분석> ch10 KNN\",\n  \"date\": \"2020-08-24T00:00:00.000Z\",\n  \"tags\": [\"Python\", \"BigData\", \"MachineLearning\"]\n};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component '\" + name + \"' was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h3\", null, \"KNN\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uC9C0\\uB3C4\\uD559\\uC2B5, \\uBD84\\uB958 \\uC54C\\uACE0\\uB9AC\\uC998\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uC8FC\\uC5B4\\uC9C4 \\uB370\\uC774\\uD130\\uB85C\\uBD80\\uD130 \\uAC70\\uB9AC\\uAC00 \\uAC00\\uAE4C\\uC6B4 k\\uAC1C\\uC758 \\uB2E4\\uB978 \\uB370\\uC774\\uD130\\uB4E4\\uC758 \\uB77C\\uBCA8 \\uC911 \\uAC00\\uC7A5 \\uB9CE\\uC740 \\uBE44\\uC728\\uC744 \\uCC28\\uC9C0\\uD558\\uB294 \\uB77C\\uBCA8\\uC744 \\uCC38\\uC870\\uD558\\uC5EC \\uBD84\\uB958\\uD558\\uB294 \\uC54C\\uACE0\\uB9AC\\uC998\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uC0AC\\uB840 \\uAE30\\uBC18 \\uC54C\\uACE0\\uB9AC\\uC998\\uC758 \\uD55C \\uC885\\uB958\\uB85C \\uB370\\uC774\\uD130 \\uC591\\uC774 \\uB9CE\\uC544\\uC9C0\\uBA74 \\uC18D\\uB3C4\\uAC00 \\uB290\\uB824\\uC9C8 \\uC218 \\uC788\\uC74C\")), mdx(\"h4\", null, \"K \\uAC1C\\uC218 \\uCD5C\\uC801\\uD654 \\uBB38\\uC81C\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"k\\uAC12\\uC774 \\uD074 \\uB54C \\uC804\\uCCB4\\uC801\\uC778 \\uB178\\uC774\\uC988\\uB97C \\uC904\\uC77C \\uC218 \\uC788\\uC9C0\\uB9CC \\uC911\\uC694\\uD55C \\uD328\\uD134\\uC744 \\uBB34\\uC2DC\\uD560 \\uAC00\\uB2A5\\uC131\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uCD5C\\uC801\\uC758 K\\uAC12\\uC744 \\uCC3E\\uAE30 \\uC704\\uD574 K-fold Cross-validation \\uBC29\\uBC95\\uC744 \\uD65C\\uC6A9\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"k=1\\uC77C \\uB54C \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"over-fitting\"), \" \\uB420 \\uC218 \\uC788\\uC74C\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"k\\uAC12\\uC774 \\uB108\\uBB34 \\uD074 \\uB54C \\uC0C8\\uB85C\\uC6B4 \\uB370\\uC774\\uD130\\uC758 \\uB77C\\uBCA8\\uC740 \\uD56D\\uC0C1 \\uC804\\uCCB4 \\uB370\\uC774\\uD130\\uC758 \\uB300\\uB2E4\\uC218\\uB97C \\uCC28\\uC9C0\\uD558\\uB294 \\uB77C\\uBCA8\\uB85C \\uBD84\\uB958\\uD558\\uB294 \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"under fitting\"), \" \\uBB38\\uC81C \\uBC1C\\uC0DD\")), mdx(\"hr\", null), mdx(\"h3\", null, \"KNN \\uC2E4\\uC2B5\"), mdx(\"h4\", null, \"\\uD328\\uD0A4\\uC9C0 , \\uB370\\uC774\\uD130 \\uB85C\\uB4DC\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"from sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.model_selection import cross_val_score\\n\\nimport pandas as pd\\nimport numpy as np\\n\\nfrom sklearn.datasets import load_breast_cancer\\nfrom sklearn.preprocessing import normalize\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"breast_cancer = load_breast_cancer()\\nX = breast_cancer.data\\ny = breast_cancer.target\\n\\ndf = pd.DataFrame(X,columns = breast_cancer.feature_names)\\n\")), mdx(\"h4\", null, \"\\uB370\\uC774\\uD130 \\uC14B \\uBD84\\uB9AC\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33, random_state = 42)\\n\")), mdx(\"h4\", null, \"\\uBAA8\\uB378 \\uD559\\uC2B5 \\uBC0F \\uC815\\uD655\\uB3C4 \\uCE21\\uC815\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"estimator = KNeighborsClassifier(n_neighbors=5, weights = 'distance')\\n\\nestimator.fit(X_train,y_train)\\n\\nlabel_predict = estimator.predict(X_test)\\n\\nprint(\\\"The accuracy score of classification: %.9f\\\"%accuracy_score(y_test,label_predict))\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"The accuracy score of classification: 0.941489362\\n\")), mdx(\"h4\", null, \"Cross Validation\\uBC29\\uBC95\\uC744 \\uC0AC\\uC6A9\\uD558\\uC5EC \\uCD5C\\uC801\\uC758 k\\uAC12\\uC744 \\uCC3E\\uAE30\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"myList = list(range(1,100))\\nneighbors = [ x for x in myList if x%2!=0]\\nprint(\\\"k\\uC758 \\uD6C4\\uBCF4\\uAC12\\uB4E4 \\uCD94\\uCD9C\\\",neighbors)\\ncv_scores = []\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"k\\uC758 \\uD6C4\\uBCF4\\uAC12\\uB4E4 \\uCD94\\uCD9C [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 69, 71, 73, 75, 77, 79, 81, 83, 85, 87, 89, 91, 93, 95, 97, 99]\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"for k in neighbors:\\n    print(\\\"< k = %d >\\\"%k)\\n    estimator = KNeighborsClassifier(n_neighbors=k)\\n    scores = cross_val_score(estimator, X_train, y_train, cv=10,scoring=\\\"accuracy\\\")\\n    print(\\\"The scores of classification are \\\\n\\\"+str(scores))\\n    cv_scores.append(scores.mean())\\n    print(\\\"The average score of score is %.9f \\\\n\\\"%scores.mean())\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"< k = 1 >\\nThe scores of classification are \\n[0.97435897 0.84210526 0.92105263 0.97368421 0.81578947 0.89473684\\n 0.89473684 0.89473684 0.89473684 0.84210526]\\nThe average score of score is 0.894804318 \\n\\n< k = 3 >\\nThe scores of classification are \\n[0.94871795 0.86842105 0.89473684 0.94736842 0.94736842 0.89473684\\n 0.86842105 0.89473684 0.94736842 0.81578947]\\nThe average score of score is 0.902766532 \\n\\n< k = 5 >\\nThe scores of classification are \\n[0.94871795 0.86842105 0.89473684 0.94736842 0.94736842 0.92105263\\n 0.94736842 0.86842105 0.92105263 0.81578947]\\nThe average score of score is 0.908029690 \\n\\n...\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"MSE = [1 - x for x in cv_scores]\\n\\nplt.plot(neighbors, MSE)\\nplt.xlabel(\\\"Number of Neighbors K\\\")\\nplt.ylabel(\\\"Misclassification Error\\\")\\nplt.show()\\n\\nmin_MSE = min(MSE)\\nindex_of_min_MSE = MSE.index(min_MSE)\\noptimal_k = neighbors[index_of_min_MSE]\\nprint(\\\"The optimal number of neighbors i is %d\\\"%optimal_k)\\n\")), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"398px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"65.83333333333333%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAACJElEQVQ4y52Tz2sTQRTHR6soShOC8SBC78UfqCf/DosKRQ/F/jceQpJTLkFUME1EcsjJhAoi2kBI0lP8leBqU7bJ/t6d/TXZGd9sNttFDBUffJk3b5cP7ztvBhUKhVMIodPlcnlNFMUXqqrWZFneURSlygV5vOqqWj2aStWJJMU1cSJVP/84rEiy8kYQhKcon8+vAPBspVK5HQQBOykcEEnsTcrYF3lesS3zOxqPx2GHtVrthuu6OtQphA8iSc2CgPyUMREki4xVmzj+jNgeIZLpEmjEN33KFFXromw2exmAZ+r1+nXP8zCLiNHKopT9UjATdScUgNnEcNmBYjPZcvnn0BoA91E6nb4KwHO16s5NbDshMCQmYLOAMhV7sU0Owx5hiuUxw/FjoK7r+yiVSq3xDj/svr021Sw8ozEyBpoOgU6OgYt6Yg2BmqbFwAuvX728JenYwv7cbXIQX0UjhC6B/RW48vH9u3XVxNaB5nIrFA6dWS4JrSqR3T8gSR0DM5nMFQCuPn9WvmNgxzrUXSbIFoVp0qnpUpgkhQnT6FyXxQLYR4toNpvrvufpgmIH3474JQivG5fPTs69aChdlMvl+MVeLRaLdwmZn5M5Y/8V8MqGqNVqhR2WSqV0p9N5NJ1MHsrS9P6nvb3t0Wi0CTY22u32k+FwuGma5r1ut7s1GAweG4ax0ev1tvie1/v9/naj0XiA/jGy/HmCzoMugS4u+/E3q0crOwiO0/IAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"img\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"png\",\n    \"title\": \"png\",\n    \"src\": \"/static/f715c329e1cf56f8e36d6f99890f4564/48cfd/ch10_25_0.png\",\n    \"srcSet\": [\"/static/f715c329e1cf56f8e36d6f99890f4564/5243c/ch10_25_0.png 240w\", \"/static/f715c329e1cf56f8e36d6f99890f4564/48cfd/ch10_25_0.png 398w\"],\n    \"sizes\": \"(max-width: 398px) 100vw, 398px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  })), \"\\n    \")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"The optimal number of neighbors i is 13\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"estimator = KNeighborsClassifier(n_neighbors =13)\\nestimator.fit(X_train,y_train)\\n\\nlabel_predict = estimator.predict(X_test)\\n\\nprint(\\\"accuracy: %.9f\\\"%accuracy_score(y_test, label_predict))\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"accuracy: 0.962765957\\n\")));\n}\n;\nMDXContent.isMDXComponent = true;","rawMDXOutput":"/* @jsx mdx */\nimport { mdx } from '@mdx-js/react';\n/* @jsx mdx */\n\nexport const _frontmatter = {\n  \"title\": \"<파이썬을 이용한 빅데이터 분석> ch10 KNN\",\n  \"date\": \"2020-08-24T00:00:00.000Z\",\n  \"tags\": [\"Python\", \"BigData\", \"MachineLearning\"]\n};\nconst makeShortcode = name => function MDXDefaultShortcode(props) {\n  console.warn(\"Component '\" + name + \"' was not imported, exported, or provided by MDXProvider as global scope\")\n  return <div {...props}/>\n};\n\nconst layoutProps = {\n  _frontmatter\n};\nconst MDXLayout = \"wrapper\"\nexport default function MDXContent({\n  components,\n  ...props\n}) {\n  return <MDXLayout {...layoutProps} {...props} components={components} mdxType=\"MDXLayout\">\n    <h3>{`KNN`}</h3>\n    <ul>\n      <li parentName=\"ul\">{`지도학습, 분류 알고리즘`}</li>\n      <li parentName=\"ul\">{`주어진 데이터로부터 거리가 가까운 k개의 다른 데이터들의 라벨 중 가장 많은 비율을 차지하는 라벨을 참조하여 분류하는 알고리즘`}</li>\n      <li parentName=\"ul\">{`사례 기반 알고리즘의 한 종류로 데이터 양이 많아지면 속도가 느려질 수 있음`}</li>\n    </ul>\n    <h4>{`K 개수 최적화 문제`}</h4>\n    <ul>\n      <li parentName=\"ul\">{`k값이 클 때 전체적인 노이즈를 줄일 수 있지만 중요한 패턴을 무시할 가능성`}</li>\n      <li parentName=\"ul\">{`최적의 K값을 찾기 위해 K-fold Cross-validation 방법을 활용`}</li>\n      <li parentName=\"ul\">{`k=1일 때 `}<strong parentName=\"li\">{`over-fitting`}</strong>{` 될 수 있음`}</li>\n      <li parentName=\"ul\">{`k값이 너무 클 때 새로운 데이터의 라벨은 항상 전체 데이터의 대다수를 차지하는 라벨로 분류하는 `}<strong parentName=\"li\">{`under fitting`}</strong>{` 문제 발생`}</li>\n    </ul>\n    <hr></hr>\n    <h3>{`KNN 실습`}</h3>\n    <h4>{`패키지 , 데이터 로드`}</h4>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.preprocessing import normalize\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`breast_cancer = load_breast_cancer()\nX = breast_cancer.data\ny = breast_cancer.target\n\ndf = pd.DataFrame(X,columns = breast_cancer.feature_names)\n`}</code></pre>\n    <h4>{`데이터 셋 분리`}</h4>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33, random_state = 42)\n`}</code></pre>\n    <h4>{`모델 학습 및 정확도 측정`}</h4>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`estimator = KNeighborsClassifier(n_neighbors=5, weights = 'distance')\n\nestimator.fit(X_train,y_train)\n\nlabel_predict = estimator.predict(X_test)\n\nprint(\"The accuracy score of classification: %.9f\"%accuracy_score(y_test,label_predict))\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`The accuracy score of classification: 0.941489362\n`}</code></pre>\n    <h4>{`Cross Validation방법을 사용하여 최적의 k값을 찾기`}</h4>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`myList = list(range(1,100))\nneighbors = [ x for x in myList if x%2!=0]\nprint(\"k의 후보값들 추출\",neighbors)\ncv_scores = []\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`k의 후보값들 추출 [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 69, 71, 73, 75, 77, 79, 81, 83, 85, 87, 89, 91, 93, 95, 97, 99]\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`for k in neighbors:\n    print(\"< k = %d >\"%k)\n    estimator = KNeighborsClassifier(n_neighbors=k)\n    scores = cross_val_score(estimator, X_train, y_train, cv=10,scoring=\"accuracy\")\n    print(\"The scores of classification are \\\\n\"+str(scores))\n    cv_scores.append(scores.mean())\n    print(\"The average score of score is %.9f \\\\n\"%scores.mean())\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`< k = 1 >\nThe scores of classification are \n[0.97435897 0.84210526 0.92105263 0.97368421 0.81578947 0.89473684\n 0.89473684 0.89473684 0.89473684 0.84210526]\nThe average score of score is 0.894804318 \n\n< k = 3 >\nThe scores of classification are \n[0.94871795 0.86842105 0.89473684 0.94736842 0.94736842 0.89473684\n 0.86842105 0.89473684 0.94736842 0.81578947]\nThe average score of score is 0.902766532 \n\n< k = 5 >\nThe scores of classification are \n[0.94871795 0.86842105 0.89473684 0.94736842 0.94736842 0.92105263\n 0.94736842 0.86842105 0.92105263 0.81578947]\nThe average score of score is 0.908029690 \n\n...\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`MSE = [1 - x for x in cv_scores]\n\nplt.plot(neighbors, MSE)\nplt.xlabel(\"Number of Neighbors K\")\nplt.ylabel(\"Misclassification Error\")\nplt.show()\n\nmin_MSE = min(MSE)\nindex_of_min_MSE = MSE.index(min_MSE)\noptimal_k = neighbors[index_of_min_MSE]\nprint(\"The optimal number of neighbors i is %d\"%optimal_k)\n`}</code></pre>\n    <p><span parentName=\"p\" {...{\n        \"className\": \"gatsby-resp-image-wrapper\",\n        \"style\": {\n          \"position\": \"relative\",\n          \"display\": \"block\",\n          \"marginLeft\": \"auto\",\n          \"marginRight\": \"auto\",\n          \"maxWidth\": \"398px\"\n        }\n      }}>{`\n      `}<span parentName=\"span\" {...{\n          \"className\": \"gatsby-resp-image-background-image\",\n          \"style\": {\n            \"paddingBottom\": \"65.83333333333333%\",\n            \"position\": \"relative\",\n            \"bottom\": \"0\",\n            \"left\": \"0\",\n            \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAACJElEQVQ4y52Tz2sTQRTHR6soShOC8SBC78UfqCf/DosKRQ/F/jceQpJTLkFUME1EcsjJhAoi2kBI0lP8leBqU7bJ/t6d/TXZGd9sNttFDBUffJk3b5cP7ztvBhUKhVMIodPlcnlNFMUXqqrWZFneURSlygV5vOqqWj2aStWJJMU1cSJVP/84rEiy8kYQhKcon8+vAPBspVK5HQQBOykcEEnsTcrYF3lesS3zOxqPx2GHtVrthuu6OtQphA8iSc2CgPyUMREki4xVmzj+jNgeIZLpEmjEN33KFFXromw2exmAZ+r1+nXP8zCLiNHKopT9UjATdScUgNnEcNmBYjPZcvnn0BoA91E6nb4KwHO16s5NbDshMCQmYLOAMhV7sU0Owx5hiuUxw/FjoK7r+yiVSq3xDj/svr021Sw8ozEyBpoOgU6OgYt6Yg2BmqbFwAuvX728JenYwv7cbXIQX0UjhC6B/RW48vH9u3XVxNaB5nIrFA6dWS4JrSqR3T8gSR0DM5nMFQCuPn9WvmNgxzrUXSbIFoVp0qnpUpgkhQnT6FyXxQLYR4toNpvrvufpgmIH3474JQivG5fPTs69aChdlMvl+MVeLRaLdwmZn5M5Y/8V8MqGqNVqhR2WSqV0p9N5NJ1MHsrS9P6nvb3t0Wi0CTY22u32k+FwuGma5r1ut7s1GAweG4ax0ev1tvie1/v9/naj0XiA/jGy/HmCzoMugS4u+/E3q0crOwiO0/IAAAAASUVORK5CYII=')\",\n            \"backgroundSize\": \"cover\",\n            \"display\": \"block\"\n          }\n        }}></span>{`\n  `}<img parentName=\"span\" {...{\n          \"className\": \"gatsby-resp-image-image\",\n          \"alt\": \"png\",\n          \"title\": \"png\",\n          \"src\": \"/static/f715c329e1cf56f8e36d6f99890f4564/48cfd/ch10_25_0.png\",\n          \"srcSet\": [\"/static/f715c329e1cf56f8e36d6f99890f4564/5243c/ch10_25_0.png 240w\", \"/static/f715c329e1cf56f8e36d6f99890f4564/48cfd/ch10_25_0.png 398w\"],\n          \"sizes\": \"(max-width: 398px) 100vw, 398px\",\n          \"style\": {\n            \"width\": \"100%\",\n            \"height\": \"100%\",\n            \"margin\": \"0\",\n            \"verticalAlign\": \"middle\",\n            \"position\": \"absolute\",\n            \"top\": \"0\",\n            \"left\": \"0\"\n          },\n          \"loading\": \"lazy\"\n        }}></img>{`\n    `}</span></p>\n    <pre><code parentName=\"pre\" {...{}}>{`The optimal number of neighbors i is 13\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`estimator = KNeighborsClassifier(n_neighbors =13)\nestimator.fit(X_train,y_train)\n\nlabel_predict = estimator.predict(X_test)\n\nprint(\"accuracy: %.9f\"%accuracy_score(y_test, label_predict))\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`accuracy: 0.962765957\n`}</code></pre>\n\n    </MDXLayout>;\n}\n\n;\nMDXContent.isMDXComponent = true;"}}