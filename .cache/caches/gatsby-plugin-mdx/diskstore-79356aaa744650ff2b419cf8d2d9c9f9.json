{"expireTime":9007200852250420000,"key":"gatsby-plugin-mdx-entire-payload-cfdc29e94627f8e2161a566613cd9192-","val":{"mdast":{"type":"root","children":[{"type":"heading","depth":3,"children":[{"type":"text","value":"랜덤 포레스트란","position":{"start":{"line":2,"column":5,"offset":5},"end":{"line":2,"column":13,"offset":13},"indent":[]}}],"position":{"start":{"line":2,"column":1,"offset":1},"end":{"line":2,"column":13,"offset":13},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"결정트리의 확장, 단점을 개선하기 위한 알고리즘 중 하나","position":{"start":{"line":4,"column":3,"offset":17},"end":{"line":4,"column":34,"offset":48},"indent":[]}}],"position":{"start":{"line":4,"column":3,"offset":17},"end":{"line":4,"column":34,"offset":48},"indent":[]}}],"position":{"start":{"line":4,"column":1,"offset":15},"end":{"line":4,"column":34,"offset":48},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"데이터 분류, 군집, 데이터에서 특징의 중요성 확인","position":{"start":{"line":5,"column":3,"offset":51},"end":{"line":5,"column":31,"offset":79},"indent":[]}}],"position":{"start":{"line":5,"column":3,"offset":51},"end":{"line":5,"column":31,"offset":79},"indent":[]}}],"position":{"start":{"line":5,"column":1,"offset":49},"end":{"line":5,"column":31,"offset":79},"indent":[]}}],"position":{"start":{"line":4,"column":1,"offset":15},"end":{"line":5,"column":31,"offset":79},"indent":[1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"랜덤포레스트 예측 모듈 생성과정","position":{"start":{"line":7,"column":5,"offset":85},"end":{"line":7,"column":22,"offset":102},"indent":[]}}],"position":{"start":{"line":7,"column":1,"offset":81},"end":{"line":7,"column":22,"offset":102},"indent":[]}},{"type":"list","ordered":true,"start":1,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Dataset에서 샘플 데이터를 선택","position":{"start":{"line":9,"column":4,"offset":107},"end":{"line":9,"column":24,"offset":127},"indent":[]}}],"position":{"start":{"line":9,"column":4,"offset":107},"end":{"line":9,"column":24,"offset":127},"indent":[]}}],"position":{"start":{"line":9,"column":1,"offset":104},"end":{"line":9,"column":24,"offset":127},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"샘플 데이터를 이용해 결정트리 생성","position":{"start":{"line":10,"column":4,"offset":131},"end":{"line":10,"column":23,"offset":150},"indent":[]}}],"position":{"start":{"line":10,"column":4,"offset":131},"end":{"line":10,"column":23,"offset":150},"indent":[]}}],"position":{"start":{"line":10,"column":1,"offset":128},"end":{"line":10,"column":23,"offset":150},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"1과2를 n번 반복","position":{"start":{"line":11,"column":4,"offset":154},"end":{"line":11,"column":14,"offset":164},"indent":[]}}],"position":{"start":{"line":11,"column":4,"offset":154},"end":{"line":11,"column":14,"offset":164},"indent":[]}}],"position":{"start":{"line":11,"column":1,"offset":151},"end":{"line":11,"column":14,"offset":164},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"3을 통해 생성한 n개의 결정트리를 이용해 예측","position":{"start":{"line":12,"column":4,"offset":168},"end":{"line":12,"column":30,"offset":194},"indent":[]}}],"position":{"start":{"line":12,"column":4,"offset":168},"end":{"line":12,"column":30,"offset":194},"indent":[]}}],"position":{"start":{"line":12,"column":1,"offset":165},"end":{"line":12,"column":30,"offset":194},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"예측 결과에서 가장 많이 등장한 결과를 선택하여 최종 결과로 선택","position":{"start":{"line":13,"column":4,"offset":198},"end":{"line":13,"column":40,"offset":234},"indent":[]}}],"position":{"start":{"line":13,"column":4,"offset":198},"end":{"line":13,"column":40,"offset":234},"indent":[]}}],"position":{"start":{"line":13,"column":1,"offset":195},"end":{"line":13,"column":40,"offset":234},"indent":[]}}],"position":{"start":{"line":9,"column":1,"offset":104},"end":{"line":13,"column":40,"offset":234},"indent":[1,1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"랜덤 포레스트 특징","position":{"start":{"line":15,"column":5,"offset":240},"end":{"line":15,"column":15,"offset":250},"indent":[]}}],"position":{"start":{"line":15,"column":1,"offset":236},"end":{"line":15,"column":15,"offset":250},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"여러 개의 결정트리를 결합함으로써 단일 결정트리의 결점을 극복","position":{"start":{"line":17,"column":3,"offset":254},"end":{"line":17,"column":37,"offset":288},"indent":[]}}],"position":{"start":{"line":17,"column":3,"offset":254},"end":{"line":17,"column":37,"offset":288},"indent":[]}}],"position":{"start":{"line":17,"column":1,"offset":252},"end":{"line":17,"column":37,"offset":288},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Overfitting 문제가 적음","position":{"start":{"line":18,"column":3,"offset":291},"end":{"line":18,"column":21,"offset":309},"indent":[]}}],"position":{"start":{"line":18,"column":3,"offset":291},"end":{"line":18,"column":21,"offset":309},"indent":[]}}],"position":{"start":{"line":18,"column":1,"offset":289},"end":{"line":18,"column":21,"offset":309},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"구현이 간단","position":{"start":{"line":19,"column":3,"offset":312},"end":{"line":19,"column":9,"offset":318},"indent":[]}}],"position":{"start":{"line":19,"column":3,"offset":312},"end":{"line":19,"column":9,"offset":318},"indent":[]}}],"position":{"start":{"line":19,"column":1,"offset":310},"end":{"line":19,"column":9,"offset":318},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"병렬 계산이 간단","position":{"start":{"line":20,"column":3,"offset":321},"end":{"line":20,"column":12,"offset":330},"indent":[]}}],"position":{"start":{"line":20,"column":3,"offset":321},"end":{"line":20,"column":12,"offset":330},"indent":[]}}],"position":{"start":{"line":20,"column":1,"offset":319},"end":{"line":20,"column":12,"offset":330},"indent":[]}}],"position":{"start":{"line":17,"column":1,"offset":252},"end":{"line":20,"column":12,"offset":330},"indent":[1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"랜덤포레스트에서의 Random","position":{"start":{"line":22,"column":5,"offset":336},"end":{"line":22,"column":21,"offset":352},"indent":[]}}],"position":{"start":{"line":22,"column":1,"offset":332},"end":{"line":22,"column":21,"offset":352},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"데이터 셋에서 샘플데이터를 random으로 선택","position":{"start":{"line":23,"column":3,"offset":355},"end":{"line":23,"column":29,"offset":381},"indent":[]}}],"position":{"start":{"line":23,"column":3,"offset":355},"end":{"line":23,"column":29,"offset":381},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"데이터는 중복선택을 함","position":{"start":{"line":24,"column":7,"offset":388},"end":{"line":24,"column":19,"offset":400},"indent":[]}}],"position":{"start":{"line":24,"column":7,"offset":388},"end":{"line":24,"column":19,"offset":400},"indent":[]}}],"position":{"start":{"line":24,"column":3,"offset":384},"end":{"line":24,"column":19,"offset":400},"indent":[]}}],"position":{"start":{"line":24,"column":3,"offset":384},"end":{"line":24,"column":19,"offset":400},"indent":[]}}],"position":{"start":{"line":23,"column":1,"offset":353},"end":{"line":24,"column":19,"offset":400},"indent":[1]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"선택한 샘플 데이터에서 random으로 feature를 선택","position":{"start":{"line":25,"column":3,"offset":403},"end":{"line":25,"column":36,"offset":436},"indent":[]}}],"position":{"start":{"line":25,"column":3,"offset":403},"end":{"line":25,"column":36,"offset":436},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"feature의 개수는 전체 feature수의 제곱근, log2 등 방법으로 계산","position":{"start":{"line":26,"column":7,"offset":443},"end":{"line":26,"column":52,"offset":488},"indent":[]}}],"position":{"start":{"line":26,"column":7,"offset":443},"end":{"line":26,"column":52,"offset":488},"indent":[]}}],"position":{"start":{"line":26,"column":3,"offset":439},"end":{"line":26,"column":52,"offset":488},"indent":[]}}],"position":{"start":{"line":26,"column":3,"offset":439},"end":{"line":26,"column":52,"offset":488},"indent":[]}}],"position":{"start":{"line":25,"column":1,"offset":401},"end":{"line":26,"column":52,"offset":488},"indent":[1]}}],"position":{"start":{"line":23,"column":1,"offset":353},"end":{"line":26,"column":52,"offset":488},"indent":[1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"자기 성능 평가","position":{"start":{"line":27,"column":5,"offset":493},"end":{"line":27,"column":13,"offset":501},"indent":[]}}],"position":{"start":{"line":27,"column":1,"offset":489},"end":{"line":27,"column":13,"offset":501},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Bagging (Bootstrap Aggregation)","position":{"start":{"line":29,"column":3,"offset":505},"end":{"line":29,"column":34,"offset":536},"indent":[]}}],"position":{"start":{"line":29,"column":3,"offset":505},"end":{"line":29,"column":34,"offset":536},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"63%의 데이터를 이용해 각각의 트리를 생성","position":{"start":{"line":30,"column":7,"offset":543},"end":{"line":30,"column":31,"offset":567},"indent":[]}}],"position":{"start":{"line":30,"column":7,"offset":543},"end":{"line":30,"column":31,"offset":567},"indent":[]}}],"position":{"start":{"line":30,"column":3,"offset":539},"end":{"line":30,"column":31,"offset":567},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"나머지 37%의 데이터를 이용해 각각의 트리의 성능을 평가","position":{"start":{"line":31,"column":7,"offset":574},"end":{"line":31,"column":39,"offset":606},"indent":[]}}],"position":{"start":{"line":31,"column":7,"offset":574},"end":{"line":31,"column":39,"offset":606},"indent":[]}}],"position":{"start":{"line":31,"column":3,"offset":570},"end":{"line":31,"column":39,"offset":606},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"각각의 트리에 입력하는 데이터는 다름","position":{"start":{"line":32,"column":7,"offset":613},"end":{"line":32,"column":27,"offset":633},"indent":[]}}],"position":{"start":{"line":32,"column":7,"offset":613},"end":{"line":32,"column":27,"offset":633},"indent":[]}}],"position":{"start":{"line":32,"column":3,"offset":609},"end":{"line":32,"column":27,"offset":633},"indent":[]}}],"position":{"start":{"line":30,"column":3,"offset":539},"end":{"line":32,"column":27,"offset":633},"indent":[3,3]}}],"position":{"start":{"line":29,"column":1,"offset":503},"end":{"line":32,"column":27,"offset":633},"indent":[1,1,1]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Out-of-Bag (OOB)","position":{"start":{"line":33,"column":3,"offset":636},"end":{"line":33,"column":19,"offset":652},"indent":[]}}],"position":{"start":{"line":33,"column":3,"offset":636},"end":{"line":33,"column":19,"offset":652},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"OOB 데이터를 이용해 tree의 성능을 교정","position":{"start":{"line":34,"column":7,"offset":659},"end":{"line":34,"column":32,"offset":684},"indent":[]}}],"position":{"start":{"line":34,"column":7,"offset":659},"end":{"line":34,"column":32,"offset":684},"indent":[]}}],"position":{"start":{"line":34,"column":3,"offset":655},"end":{"line":34,"column":32,"offset":684},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"OOB는 성능통계에서 많이 사용됨","position":{"start":{"line":35,"column":7,"offset":691},"end":{"line":35,"column":25,"offset":709},"indent":[]}}],"position":{"start":{"line":35,"column":7,"offset":691},"end":{"line":35,"column":25,"offset":709},"indent":[]}}],"position":{"start":{"line":35,"column":3,"offset":687},"end":{"line":35,"column":25,"offset":709},"indent":[]}}],"position":{"start":{"line":34,"column":3,"offset":655},"end":{"line":35,"column":25,"offset":709},"indent":[3]}}],"position":{"start":{"line":33,"column":1,"offset":634},"end":{"line":35,"column":25,"offset":709},"indent":[1,1]}}],"position":{"start":{"line":29,"column":1,"offset":503},"end":{"line":35,"column":25,"offset":709},"indent":[1,1,1,1,1,1]}},{"type":"thematicBreak","position":{"start":{"line":38,"column":1,"offset":712},"end":{"line":38,"column":4,"offset":715},"indent":[]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"붓꽃 데이터 실습","position":{"start":{"line":40,"column":5,"offset":721},"end":{"line":40,"column":14,"offset":730},"indent":[]}}],"position":{"start":{"line":40,"column":1,"offset":717},"end":{"line":40,"column":14,"offset":730},"indent":[]}},{"type":"heading","depth":4,"children":[{"type":"text","value":"패키지 로드","position":{"start":{"line":42,"column":6,"offset":737},"end":{"line":42,"column":12,"offset":743},"indent":[]}}],"position":{"start":{"line":42,"column":1,"offset":732},"end":{"line":42,"column":12,"offset":743},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"from sklearn.datasets import load_iris\nfrom sklearn.metrics import accuracy_score\nimport numpy as np\nimport pandas as pd","position":{"start":{"line":45,"column":1,"offset":746},"end":{"line":50,"column":4,"offset":880},"indent":[1,1,1,1,1]}},{"type":"heading","depth":4,"children":[{"type":"text","value":"데이터 분리","position":{"start":{"line":52,"column":6,"offset":887},"end":{"line":52,"column":12,"offset":893},"indent":[]}}],"position":{"start":{"line":52,"column":1,"offset":882},"end":{"line":52,"column":12,"offset":893},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"iris = load_iris()\n\nfrom sklearn.model_selection import train_test_split\nx = iris.data\ny = iris.target\nX_train, X_test, Y_train, Y_test = train_test_split(x,y,test_size=0.2)","position":{"start":{"line":55,"column":1,"offset":896},"end":{"line":62,"column":4,"offset":1083},"indent":[1,1,1,1,1,1,1]}},{"type":"heading","depth":4,"children":[{"type":"text","value":"랜덤 포레스트 분류기 생성","position":{"start":{"line":64,"column":6,"offset":1090},"end":{"line":64,"column":20,"offset":1104},"indent":[]}}],"position":{"start":{"line":64,"column":1,"offset":1085},"end":{"line":64,"column":20,"offset":1104},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(n_estimators=10)\nrfc","position":{"start":{"line":67,"column":1,"offset":1107},"end":{"line":72,"column":4,"offset":1223},"indent":[1,1,1,1,1]}},{"type":"code","lang":null,"meta":null,"value":"RandomForestClassifier(n_estimators=10)","position":{"start":{"line":77,"column":1,"offset":1228},"end":{"line":77,"column":44,"offset":1271},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"n_estimators=10 : 트리의 개수 10인 랜던포래스트 분류모델을 생성","position":{"start":{"line":81,"column":1,"offset":1275},"end":{"line":81,"column":45,"offset":1319},"indent":[]}}],"position":{"start":{"line":81,"column":1,"offset":1275},"end":{"line":81,"column":45,"offset":1319},"indent":[]}},{"type":"heading","depth":4,"children":[{"type":"text","value":"랜덤 포레스트 분류 학습","position":{"start":{"line":83,"column":6,"offset":1326},"end":{"line":83,"column":19,"offset":1339},"indent":[]}}],"position":{"start":{"line":83,"column":1,"offset":1321},"end":{"line":83,"column":19,"offset":1339},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"rfc.fit(X_train,Y_train)\nprediction = rfc.predict(X_test)\n\n# 예측 결과\nrfc.score(X_test,Y_test)","position":{"start":{"line":86,"column":1,"offset":1342},"end":{"line":92,"column":4,"offset":1447},"indent":[1,1,1,1,1,1]}},{"type":"code","lang":null,"meta":null,"value":"0.8666666666666667","position":{"start":{"line":97,"column":1,"offset":1452},"end":{"line":97,"column":23,"offset":1474},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\n\nprint(\"Accuracy : \",accuracy_score(prediction,Y_test))\nprint(\"======================================================\")\nprint(classification_report(prediction,Y_test))","position":{"start":{"line":102,"column":1,"offset":1479},"end":{"line":109,"column":4,"offset":1753},"indent":[1,1,1,1,1,1,1]}},{"type":"code","lang":null,"meta":null,"value":"Accuracy :  0.8666666666666667\n======================================================\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00         4\n           1       1.00      0.75      0.86        16\n           2       0.71      1.00      0.83        10\n\n    accuracy                           0.87        30\n   macro avg       0.90      0.92      0.90        30\nweighted avg       0.90      0.87      0.87        30","position":{"start":{"line":111,"column":1,"offset":1755},"end":{"line":122,"column":5,"offset":2269},"indent":[1,1,1,1,1,1,1,1,1,1,1]}},{"type":"heading","depth":4,"children":[{"type":"text","value":"랜덤포레스트 분류 성능 높이는 방법","position":{"start":{"line":125,"column":6,"offset":2277},"end":{"line":125,"column":25,"offset":2296},"indent":[]}}],"position":{"start":{"line":125,"column":1,"offset":2272},"end":{"line":125,"column":25,"offset":2296},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"트리의 개수를 적당히 확장한다","position":{"start":{"line":127,"column":3,"offset":2300},"end":{"line":127,"column":19,"offset":2316},"indent":[]}}],"position":{"start":{"line":127,"column":3,"offset":2300},"end":{"line":127,"column":19,"offset":2316},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"랜덤포레스트의 성능이 높아지는 것은 아님을 주의","position":{"start":{"line":128,"column":7,"offset":2323},"end":{"line":128,"column":33,"offset":2349},"indent":[]}}],"position":{"start":{"line":128,"column":7,"offset":2323},"end":{"line":128,"column":33,"offset":2349},"indent":[]}}],"position":{"start":{"line":128,"column":3,"offset":2319},"end":{"line":128,"column":33,"offset":2349},"indent":[]}}],"position":{"start":{"line":128,"column":3,"offset":2319},"end":{"line":128,"column":33,"offset":2349},"indent":[]}}],"position":{"start":{"line":127,"column":1,"offset":2298},"end":{"line":128,"column":33,"offset":2349},"indent":[1]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"max_features 값을 수정","position":{"start":{"line":129,"column":3,"offset":2352},"end":{"line":129,"column":21,"offset":2370},"indent":[]}}],"position":{"start":{"line":129,"column":3,"offset":2352},"end":{"line":129,"column":21,"offset":2370},"indent":[]}}],"position":{"start":{"line":129,"column":1,"offset":2350},"end":{"line":129,"column":21,"offset":2370},"indent":[]}}],"position":{"start":{"line":127,"column":1,"offset":2298},"end":{"line":129,"column":21,"offset":2370},"indent":[1,1]}},{"type":"code","lang":"python","meta":null,"value":"rfc2 = RandomForestClassifier(n_estimators=200,\n                              max_features=4,\n                              oob_score=True)\n\nrfc2.fit(X_train,Y_train)\nprediction2 = rfc2.predict(X_test)\nprint(\"Accuracy : \",accuracy_score(prediction2,Y_test))\nprint(\"======================================================\")\nprint(classification_report(prediction2,Y_test))","position":{"start":{"line":132,"column":1,"offset":2373},"end":{"line":142,"column":4,"offset":2757},"indent":[1,1,1,1,1,1,1,1,1,1]}},{"type":"code","lang":null,"meta":null,"value":"Accuracy :  0.8333333333333334\n======================================================\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00         4\n           1       1.00      0.71      0.83        17\n           2       0.64      1.00      0.78         9\n\n    accuracy                           0.83        30\n   macro avg       0.88      0.90      0.87        30\nweighted avg       0.89      0.83      0.84        30","position":{"start":{"line":144,"column":1,"offset":2759},"end":{"line":155,"column":5,"offset":3273},"indent":[1,1,1,1,1,1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"데이터가 작아서 오히려 떨어져버림..","position":{"start":{"line":158,"column":1,"offset":3276},"end":{"line":158,"column":21,"offset":3296},"indent":[]}}],"position":{"start":{"line":158,"column":1,"offset":3276},"end":{"line":158,"column":21,"offset":3296},"indent":[]}},{"type":"heading","depth":4,"children":[{"type":"text","value":"각 feature의 중요도 확인","position":{"start":{"line":160,"column":6,"offset":3303},"end":{"line":160,"column":23,"offset":3320},"indent":[]}}],"position":{"start":{"line":160,"column":1,"offset":3298},"end":{"line":160,"column":23,"offset":3320},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"for feature, imp in zip(iris.feature_names,rfc2.feature_importances_):\n    print(feature,imp)","position":{"start":{"line":163,"column":1,"offset":3323},"end":{"line":166,"column":4,"offset":3430},"indent":[1,1,1]}},{"type":"code","lang":null,"meta":null,"value":"sepal length (cm) 0.006745704725099442\nsepal width (cm) 0.005019603641588645\npetal length (cm) 0.46210977444029805\npetal width (cm) 0.5261249171930139","position":{"start":{"line":168,"column":1,"offset":3432},"end":{"line":171,"column":40,"offset":3598},"indent":[1,1,1]}},{"type":"export","value":"export const _frontmatter = {\"title\":\"<파이썬을 이용한 빅데이터 분석> ch4 랜덤포레스트\",\"date\":\"2020-08-10T00:00:00.000Z\",\"tags\":[\"Python\",\"BigData\",\"MachineLearning\"]}","position":{"start":{"line":175,"column":1,"offset":3602},"end":{"line":175,"column":150,"offset":3751},"indent":[]}}],"position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":175,"column":150,"offset":3751}}},"scopeImports":["import * as React from 'react'"],"scopeIdentifiers":["React"],"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"<파이썬을 이용한 빅데이터 분석> ch4 랜덤포레스트\",\n  \"date\": \"2020-08-10T00:00:00.000Z\",\n  \"tags\": [\"Python\", \"BigData\", \"MachineLearning\"]\n};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component '\" + name + \"' was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h3\", null, \"\\uB79C\\uB364 \\uD3EC\\uB808\\uC2A4\\uD2B8\\uB780\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uACB0\\uC815\\uD2B8\\uB9AC\\uC758 \\uD655\\uC7A5, \\uB2E8\\uC810\\uC744 \\uAC1C\\uC120\\uD558\\uAE30 \\uC704\\uD55C \\uC54C\\uACE0\\uB9AC\\uC998 \\uC911 \\uD558\\uB098\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uB370\\uC774\\uD130 \\uBD84\\uB958, \\uAD70\\uC9D1, \\uB370\\uC774\\uD130\\uC5D0\\uC11C \\uD2B9\\uC9D5\\uC758 \\uC911\\uC694\\uC131 \\uD655\\uC778\")), mdx(\"h3\", null, \"\\uB79C\\uB364\\uD3EC\\uB808\\uC2A4\\uD2B8 \\uC608\\uCE21 \\uBAA8\\uB4C8 \\uC0DD\\uC131\\uACFC\\uC815\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Dataset\\uC5D0\\uC11C \\uC0D8\\uD50C \\uB370\\uC774\\uD130\\uB97C \\uC120\\uD0DD\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"\\uC0D8\\uD50C \\uB370\\uC774\\uD130\\uB97C \\uC774\\uC6A9\\uD574 \\uACB0\\uC815\\uD2B8\\uB9AC \\uC0DD\\uC131\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"1\\uACFC2\\uB97C n\\uBC88 \\uBC18\\uBCF5\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"3\\uC744 \\uD1B5\\uD574 \\uC0DD\\uC131\\uD55C n\\uAC1C\\uC758 \\uACB0\\uC815\\uD2B8\\uB9AC\\uB97C \\uC774\\uC6A9\\uD574 \\uC608\\uCE21\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"\\uC608\\uCE21 \\uACB0\\uACFC\\uC5D0\\uC11C \\uAC00\\uC7A5 \\uB9CE\\uC774 \\uB4F1\\uC7A5\\uD55C \\uACB0\\uACFC\\uB97C \\uC120\\uD0DD\\uD558\\uC5EC \\uCD5C\\uC885 \\uACB0\\uACFC\\uB85C \\uC120\\uD0DD\")), mdx(\"h3\", null, \"\\uB79C\\uB364 \\uD3EC\\uB808\\uC2A4\\uD2B8 \\uD2B9\\uC9D5\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uC5EC\\uB7EC \\uAC1C\\uC758 \\uACB0\\uC815\\uD2B8\\uB9AC\\uB97C \\uACB0\\uD569\\uD568\\uC73C\\uB85C\\uC368 \\uB2E8\\uC77C \\uACB0\\uC815\\uD2B8\\uB9AC\\uC758 \\uACB0\\uC810\\uC744 \\uADF9\\uBCF5\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Overfitting \\uBB38\\uC81C\\uAC00 \\uC801\\uC74C\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uAD6C\\uD604\\uC774 \\uAC04\\uB2E8\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uBCD1\\uB82C \\uACC4\\uC0B0\\uC774 \\uAC04\\uB2E8\")), mdx(\"h3\", null, \"\\uB79C\\uB364\\uD3EC\\uB808\\uC2A4\\uD2B8\\uC5D0\\uC11C\\uC758 Random\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uB370\\uC774\\uD130 \\uC14B\\uC5D0\\uC11C \\uC0D8\\uD50C\\uB370\\uC774\\uD130\\uB97C random\\uC73C\\uB85C \\uC120\\uD0DD\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uB370\\uC774\\uD130\\uB294 \\uC911\\uBCF5\\uC120\\uD0DD\\uC744 \\uD568\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uC120\\uD0DD\\uD55C \\uC0D8\\uD50C \\uB370\\uC774\\uD130\\uC5D0\\uC11C random\\uC73C\\uB85C feature\\uB97C \\uC120\\uD0DD\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"feature\\uC758 \\uAC1C\\uC218\\uB294 \\uC804\\uCCB4 feature\\uC218\\uC758 \\uC81C\\uACF1\\uADFC, log2 \\uB4F1 \\uBC29\\uBC95\\uC73C\\uB85C \\uACC4\\uC0B0\")))), mdx(\"h3\", null, \"\\uC790\\uAE30 \\uC131\\uB2A5 \\uD3C9\\uAC00\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Bagging (Bootstrap Aggregation)\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"63%\\uC758 \\uB370\\uC774\\uD130\\uB97C \\uC774\\uC6A9\\uD574 \\uAC01\\uAC01\\uC758 \\uD2B8\\uB9AC\\uB97C \\uC0DD\\uC131\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uB098\\uBA38\\uC9C0 37%\\uC758 \\uB370\\uC774\\uD130\\uB97C \\uC774\\uC6A9\\uD574 \\uAC01\\uAC01\\uC758 \\uD2B8\\uB9AC\\uC758 \\uC131\\uB2A5\\uC744 \\uD3C9\\uAC00\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uAC01\\uAC01\\uC758 \\uD2B8\\uB9AC\\uC5D0 \\uC785\\uB825\\uD558\\uB294 \\uB370\\uC774\\uD130\\uB294 \\uB2E4\\uB984\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Out-of-Bag (OOB)\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"OOB \\uB370\\uC774\\uD130\\uB97C \\uC774\\uC6A9\\uD574 tree\\uC758 \\uC131\\uB2A5\\uC744 \\uAD50\\uC815\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"OOB\\uB294 \\uC131\\uB2A5\\uD1B5\\uACC4\\uC5D0\\uC11C \\uB9CE\\uC774 \\uC0AC\\uC6A9\\uB428\")))), mdx(\"hr\", null), mdx(\"h3\", null, \"\\uBD93\\uAF43 \\uB370\\uC774\\uD130 \\uC2E4\\uC2B5\"), mdx(\"h4\", null, \"\\uD328\\uD0A4\\uC9C0 \\uB85C\\uB4DC\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"from sklearn.datasets import load_iris\\nfrom sklearn.metrics import accuracy_score\\nimport numpy as np\\nimport pandas as pd\\n\")), mdx(\"h4\", null, \"\\uB370\\uC774\\uD130 \\uBD84\\uB9AC\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"iris = load_iris()\\n\\nfrom sklearn.model_selection import train_test_split\\nx = iris.data\\ny = iris.target\\nX_train, X_test, Y_train, Y_test = train_test_split(x,y,test_size=0.2)\\n\")), mdx(\"h4\", null, \"\\uB79C\\uB364 \\uD3EC\\uB808\\uC2A4\\uD2B8 \\uBD84\\uB958\\uAE30 \\uC0DD\\uC131\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"from sklearn.ensemble import RandomForestClassifier\\n\\nrfc = RandomForestClassifier(n_estimators=10)\\nrfc\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"RandomForestClassifier(n_estimators=10)\\n\")), mdx(\"p\", null, \"n_estimators=10 : \\uD2B8\\uB9AC\\uC758 \\uAC1C\\uC218 10\\uC778 \\uB79C\\uB358\\uD3EC\\uB798\\uC2A4\\uD2B8 \\uBD84\\uB958\\uBAA8\\uB378\\uC744 \\uC0DD\\uC131\"), mdx(\"h4\", null, \"\\uB79C\\uB364 \\uD3EC\\uB808\\uC2A4\\uD2B8 \\uBD84\\uB958 \\uD559\\uC2B5\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"rfc.fit(X_train,Y_train)\\nprediction = rfc.predict(X_test)\\n\\n# \\uC608\\uCE21 \\uACB0\\uACFC\\nrfc.score(X_test,Y_test)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"0.8666666666666667\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"from sklearn.metrics import accuracy_score\\nfrom sklearn.metrics import classification_report\\n\\nprint(\\\"Accuracy : \\\",accuracy_score(prediction,Y_test))\\nprint(\\\"======================================================\\\")\\nprint(classification_report(prediction,Y_test))\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"Accuracy :  0.8666666666666667\\n======================================================\\n              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00         4\\n           1       1.00      0.75      0.86        16\\n           2       0.71      1.00      0.83        10\\n\\n    accuracy                           0.87        30\\n   macro avg       0.90      0.92      0.90        30\\nweighted avg       0.90      0.87      0.87        30\\n\")), mdx(\"h4\", null, \"\\uB79C\\uB364\\uD3EC\\uB808\\uC2A4\\uD2B8 \\uBD84\\uB958 \\uC131\\uB2A5 \\uB192\\uC774\\uB294 \\uBC29\\uBC95\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uD2B8\\uB9AC\\uC758 \\uAC1C\\uC218\\uB97C \\uC801\\uB2F9\\uD788 \\uD655\\uC7A5\\uD55C\\uB2E4\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uB79C\\uB364\\uD3EC\\uB808\\uC2A4\\uD2B8\\uC758 \\uC131\\uB2A5\\uC774 \\uB192\\uC544\\uC9C0\\uB294 \\uAC83\\uC740 \\uC544\\uB2D8\\uC744 \\uC8FC\\uC758\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"max_features \\uAC12\\uC744 \\uC218\\uC815\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"rfc2 = RandomForestClassifier(n_estimators=200,\\n                              max_features=4,\\n                              oob_score=True)\\n\\nrfc2.fit(X_train,Y_train)\\nprediction2 = rfc2.predict(X_test)\\nprint(\\\"Accuracy : \\\",accuracy_score(prediction2,Y_test))\\nprint(\\\"======================================================\\\")\\nprint(classification_report(prediction2,Y_test))\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"Accuracy :  0.8333333333333334\\n======================================================\\n              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00         4\\n           1       1.00      0.71      0.83        17\\n           2       0.64      1.00      0.78         9\\n\\n    accuracy                           0.83        30\\n   macro avg       0.88      0.90      0.87        30\\nweighted avg       0.89      0.83      0.84        30\\n\")), mdx(\"p\", null, \"\\uB370\\uC774\\uD130\\uAC00 \\uC791\\uC544\\uC11C \\uC624\\uD788\\uB824 \\uB5A8\\uC5B4\\uC838\\uBC84\\uB9BC..\"), mdx(\"h4\", null, \"\\uAC01 feature\\uC758 \\uC911\\uC694\\uB3C4 \\uD655\\uC778\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"for feature, imp in zip(iris.feature_names,rfc2.feature_importances_):\\n    print(feature,imp)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"sepal length (cm) 0.006745704725099442\\nsepal width (cm) 0.005019603641588645\\npetal length (cm) 0.46210977444029805\\npetal width (cm) 0.5261249171930139\\n\")));\n}\n;\nMDXContent.isMDXComponent = true;","rawMDXOutput":"/* @jsx mdx */\nimport { mdx } from '@mdx-js/react';\n/* @jsx mdx */\n\nexport const _frontmatter = {\n  \"title\": \"<파이썬을 이용한 빅데이터 분석> ch4 랜덤포레스트\",\n  \"date\": \"2020-08-10T00:00:00.000Z\",\n  \"tags\": [\"Python\", \"BigData\", \"MachineLearning\"]\n};\nconst makeShortcode = name => function MDXDefaultShortcode(props) {\n  console.warn(\"Component '\" + name + \"' was not imported, exported, or provided by MDXProvider as global scope\")\n  return <div {...props}/>\n};\n\nconst layoutProps = {\n  _frontmatter\n};\nconst MDXLayout = \"wrapper\"\nexport default function MDXContent({\n  components,\n  ...props\n}) {\n  return <MDXLayout {...layoutProps} {...props} components={components} mdxType=\"MDXLayout\">\n    <h3>{`랜덤 포레스트란`}</h3>\n    <ul>\n      <li parentName=\"ul\">{`결정트리의 확장, 단점을 개선하기 위한 알고리즘 중 하나`}</li>\n      <li parentName=\"ul\">{`데이터 분류, 군집, 데이터에서 특징의 중요성 확인`}</li>\n    </ul>\n    <h3>{`랜덤포레스트 예측 모듈 생성과정`}</h3>\n    <ol>\n      <li parentName=\"ol\">{`Dataset에서 샘플 데이터를 선택`}</li>\n      <li parentName=\"ol\">{`샘플 데이터를 이용해 결정트리 생성`}</li>\n      <li parentName=\"ol\">{`1과2를 n번 반복`}</li>\n      <li parentName=\"ol\">{`3을 통해 생성한 n개의 결정트리를 이용해 예측`}</li>\n      <li parentName=\"ol\">{`예측 결과에서 가장 많이 등장한 결과를 선택하여 최종 결과로 선택`}</li>\n    </ol>\n    <h3>{`랜덤 포레스트 특징`}</h3>\n    <ul>\n      <li parentName=\"ul\">{`여러 개의 결정트리를 결합함으로써 단일 결정트리의 결점을 극복`}</li>\n      <li parentName=\"ul\">{`Overfitting 문제가 적음`}</li>\n      <li parentName=\"ul\">{`구현이 간단`}</li>\n      <li parentName=\"ul\">{`병렬 계산이 간단`}</li>\n    </ul>\n    <h3>{`랜덤포레스트에서의 Random`}</h3>\n    <ul>\n      <li parentName=\"ul\">{`데이터 셋에서 샘플데이터를 random으로 선택`}<ul parentName=\"li\">\n          <li parentName=\"ul\">{`데이터는 중복선택을 함`}</li>\n        </ul></li>\n      <li parentName=\"ul\">{`선택한 샘플 데이터에서 random으로 feature를 선택`}<ul parentName=\"li\">\n          <li parentName=\"ul\">{`feature의 개수는 전체 feature수의 제곱근, log2 등 방법으로 계산`}</li>\n        </ul></li>\n    </ul>\n    <h3>{`자기 성능 평가`}</h3>\n    <ul>\n      <li parentName=\"ul\">{`Bagging (Bootstrap Aggregation)`}<ul parentName=\"li\">\n          <li parentName=\"ul\">{`63%의 데이터를 이용해 각각의 트리를 생성`}</li>\n          <li parentName=\"ul\">{`나머지 37%의 데이터를 이용해 각각의 트리의 성능을 평가`}</li>\n          <li parentName=\"ul\">{`각각의 트리에 입력하는 데이터는 다름`}</li>\n        </ul></li>\n      <li parentName=\"ul\">{`Out-of-Bag (OOB)`}<ul parentName=\"li\">\n          <li parentName=\"ul\">{`OOB 데이터를 이용해 tree의 성능을 교정`}</li>\n          <li parentName=\"ul\">{`OOB는 성능통계에서 많이 사용됨`}</li>\n        </ul></li>\n    </ul>\n    <hr></hr>\n    <h3>{`붓꽃 데이터 실습`}</h3>\n    <h4>{`패키지 로드`}</h4>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`from sklearn.datasets import load_iris\nfrom sklearn.metrics import accuracy_score\nimport numpy as np\nimport pandas as pd\n`}</code></pre>\n    <h4>{`데이터 분리`}</h4>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`iris = load_iris()\n\nfrom sklearn.model_selection import train_test_split\nx = iris.data\ny = iris.target\nX_train, X_test, Y_train, Y_test = train_test_split(x,y,test_size=0.2)\n`}</code></pre>\n    <h4>{`랜덤 포레스트 분류기 생성`}</h4>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(n_estimators=10)\nrfc\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`RandomForestClassifier(n_estimators=10)\n`}</code></pre>\n    <p>{`n_estimators=10 : 트리의 개수 10인 랜던포래스트 분류모델을 생성`}</p>\n    <h4>{`랜덤 포레스트 분류 학습`}</h4>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`rfc.fit(X_train,Y_train)\nprediction = rfc.predict(X_test)\n\n# 예측 결과\nrfc.score(X_test,Y_test)\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`0.8666666666666667\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\n\nprint(\"Accuracy : \",accuracy_score(prediction,Y_test))\nprint(\"======================================================\")\nprint(classification_report(prediction,Y_test))\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`Accuracy :  0.8666666666666667\n======================================================\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00         4\n           1       1.00      0.75      0.86        16\n           2       0.71      1.00      0.83        10\n\n    accuracy                           0.87        30\n   macro avg       0.90      0.92      0.90        30\nweighted avg       0.90      0.87      0.87        30\n`}</code></pre>\n    <h4>{`랜덤포레스트 분류 성능 높이는 방법`}</h4>\n    <ul>\n      <li parentName=\"ul\">{`트리의 개수를 적당히 확장한다`}<ul parentName=\"li\">\n          <li parentName=\"ul\">{`랜덤포레스트의 성능이 높아지는 것은 아님을 주의`}</li>\n        </ul></li>\n      <li parentName=\"ul\">{`max_features 값을 수정`}</li>\n    </ul>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`rfc2 = RandomForestClassifier(n_estimators=200,\n                              max_features=4,\n                              oob_score=True)\n\nrfc2.fit(X_train,Y_train)\nprediction2 = rfc2.predict(X_test)\nprint(\"Accuracy : \",accuracy_score(prediction2,Y_test))\nprint(\"======================================================\")\nprint(classification_report(prediction2,Y_test))\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`Accuracy :  0.8333333333333334\n======================================================\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00         4\n           1       1.00      0.71      0.83        17\n           2       0.64      1.00      0.78         9\n\n    accuracy                           0.83        30\n   macro avg       0.88      0.90      0.87        30\nweighted avg       0.89      0.83      0.84        30\n`}</code></pre>\n    <p>{`데이터가 작아서 오히려 떨어져버림..`}</p>\n    <h4>{`각 feature의 중요도 확인`}</h4>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`for feature, imp in zip(iris.feature_names,rfc2.feature_importances_):\n    print(feature,imp)\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`sepal length (cm) 0.006745704725099442\nsepal width (cm) 0.005019603641588645\npetal length (cm) 0.46210977444029805\npetal width (cm) 0.5261249171930139\n`}</code></pre>\n\n    </MDXLayout>;\n}\n\n;\nMDXContent.isMDXComponent = true;"}}