{"expireTime":9007200851464154000,"key":"gatsby-plugin-mdx-entire-payload-397ebff2b211192e29f798bbf9955014-","val":{"mdast":{"type":"root","children":[{"type":"paragraph","children":[{"type":"text","value":"회귀분석은 서로 영향을 주고받으면서 인과관계를 갖는 독립변수와 종속변수 사이의 관계를 분석하는데 사용","position":{"start":{"line":3,"column":1,"offset":2},"end":{"line":3,"column":57,"offset":58},"indent":[]}}],"position":{"start":{"line":3,"column":1,"offset":2},"end":{"line":3,"column":57,"offset":58},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"종속변수와 독립변수 사이의 함수적 관계를 기술하는 수학적 방정식을 구하는데 사용","position":{"start":{"line":5,"column":1,"offset":60},"end":{"line":5,"column":45,"offset":104},"indent":[]}}],"position":{"start":{"line":5,"column":1,"offset":60},"end":{"line":5,"column":45,"offset":104},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"단일선형회귀모델","position":{"start":{"line":7,"column":4,"offset":109},"end":{"line":7,"column":12,"offset":117},"indent":[]}}],"position":{"start":{"line":7,"column":1,"offset":106},"end":{"line":7,"column":12,"offset":117},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"종속변수 Y가 독립변수 X와 오차항에 어떻게 관련되어 있는가를 나타내는 방정식","position":{"start":{"line":9,"column":1,"offset":119},"end":{"line":9,"column":44,"offset":162},"indent":[]}}],"position":{"start":{"line":9,"column":1,"offset":119},"end":{"line":9,"column":44,"offset":162},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"$$y = \\alpha + \\beta x + e$$","position":{"start":{"line":13,"column":1,"offset":167},"end":{"line":13,"column":29,"offset":195},"indent":[]}}],"position":{"start":{"line":13,"column":1,"offset":167},"end":{"line":13,"column":29,"offset":195},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Y : 종속변수","position":{"start":{"line":15,"column":3,"offset":199},"end":{"line":15,"column":11,"offset":207},"indent":[]}}],"position":{"start":{"line":15,"column":3,"offset":199},"end":{"line":15,"column":11,"offset":207},"indent":[]}}],"position":{"start":{"line":15,"column":1,"offset":197},"end":{"line":15,"column":11,"offset":207},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"ɑ : X값이 변해도 Y의 변동에는 영향을 주지 않는 회귀계수","position":{"start":{"line":16,"column":3,"offset":210},"end":{"line":16,"column":37,"offset":244},"indent":[]}}],"position":{"start":{"line":16,"column":3,"offset":210},"end":{"line":16,"column":37,"offset":244},"indent":[]}}],"position":{"start":{"line":16,"column":1,"offset":208},"end":{"line":16,"column":37,"offset":244},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"β : X의 영향력을 크기와 부호로 나타내 주는 회귀계수, X의 기울기","position":{"start":{"line":17,"column":3,"offset":247},"end":{"line":17,"column":42,"offset":286},"indent":[]}}],"position":{"start":{"line":17,"column":3,"offset":247},"end":{"line":17,"column":42,"offset":286},"indent":[]}}],"position":{"start":{"line":17,"column":1,"offset":245},"end":{"line":17,"column":42,"offset":286},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"X : 독립변수","position":{"start":{"line":18,"column":3,"offset":289},"end":{"line":18,"column":11,"offset":297},"indent":[]}}],"position":{"start":{"line":18,"column":3,"offset":289},"end":{"line":18,"column":11,"offset":297},"indent":[]}}],"position":{"start":{"line":18,"column":1,"offset":287},"end":{"line":18,"column":11,"offset":297},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"ɛ : 오차항. 독립변수 X의 값이 주어질 때 종속변수 Y의 실제값과 예측값의 차이","position":{"start":{"line":19,"column":3,"offset":300},"end":{"line":19,"column":49,"offset":346},"indent":[]}}],"position":{"start":{"line":19,"column":3,"offset":300},"end":{"line":19,"column":49,"offset":346},"indent":[]}}],"position":{"start":{"line":19,"column":1,"offset":298},"end":{"line":19,"column":49,"offset":346},"indent":[]}}],"position":{"start":{"line":15,"column":1,"offset":197},"end":{"line":19,"column":49,"offset":346},"indent":[1,1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"회귀계수 추정","position":{"start":{"line":21,"column":5,"offset":352},"end":{"line":21,"column":12,"offset":359},"indent":[]}}],"position":{"start":{"line":21,"column":1,"offset":348},"end":{"line":21,"column":12,"offset":359},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"수집된 데이터(산포도)에 가장 적절한 회귀직선을 구하는 것","position":{"start":{"line":23,"column":3,"offset":363},"end":{"line":23,"column":35,"offset":395},"indent":[]}}],"position":{"start":{"line":23,"column":3,"offset":363},"end":{"line":23,"column":35,"offset":395},"indent":[]}}],"position":{"start":{"line":23,"column":1,"offset":361},"end":{"line":23,"column":35,"offset":395},"indent":[]}}],"position":{"start":{"line":23,"column":1,"offset":361},"end":{"line":23,"column":35,"offset":395},"indent":[]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"최소자승법","position":{"start":{"line":25,"column":5,"offset":401},"end":{"line":25,"column":10,"offset":406},"indent":[]}}],"position":{"start":{"line":25,"column":1,"offset":397},"end":{"line":25,"column":10,"offset":406},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"잔차를 제곱한 값들의 합이 최소가 되도록 하는 표본회귀식의 회귀계수를 구하는 방법","position":{"start":{"line":27,"column":3,"offset":410},"end":{"line":27,"column":48,"offset":455},"indent":[]}}],"position":{"start":{"line":27,"column":3,"offset":410},"end":{"line":27,"column":48,"offset":455},"indent":[]}}],"position":{"start":{"line":27,"column":1,"offset":408},"end":{"line":27,"column":48,"offset":455},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"잔차 : X가 주어질 때 표본회귀선의 예측 값과 실제 값 사이의 차이","position":{"start":{"line":28,"column":3,"offset":458},"end":{"line":28,"column":41,"offset":496},"indent":[]}}],"position":{"start":{"line":28,"column":3,"offset":458},"end":{"line":28,"column":41,"offset":496},"indent":[]}}],"position":{"start":{"line":28,"column":1,"offset":456},"end":{"line":28,"column":41,"offset":496},"indent":[]}}],"position":{"start":{"line":27,"column":1,"offset":408},"end":{"line":28,"column":41,"offset":496},"indent":[1]}},{"type":"paragraph","children":[{"type":"text","value":"$$b = \\frac{n\\Sigma X_iY_i - \\Sigma X_i \\Sigma Y_i}{n\\Sigma (X_i)^2 - (\\Sigma X_i)^2} = \\frac{\\Sigma X_iY_i - n\\bar{X}\\bar{Y}}{\\Sigma (X_i)^2 - n(X_i)^2}$$","position":{"start":{"line":30,"column":1,"offset":498},"end":{"line":30,"column":156,"offset":653},"indent":[]}}],"position":{"start":{"line":30,"column":1,"offset":498},"end":{"line":30,"column":156,"offset":653},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"$$a = \\bar{Y} - b\\bar{X}$$","position":{"start":{"line":32,"column":1,"offset":655},"end":{"line":32,"column":27,"offset":681},"indent":[]}}],"position":{"start":{"line":32,"column":1,"offset":655},"end":{"line":32,"column":27,"offset":681},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"적합도 검증","position":{"start":{"line":34,"column":4,"offset":686},"end":{"line":34,"column":10,"offset":692},"indent":[]}}],"position":{"start":{"line":34,"column":1,"offset":683},"end":{"line":34,"column":10,"offset":692},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"표본자료를 사용하여 구한 표본회귀식이 종속변수의 값을 어느 정도 정확하게 예측할 수 있는가의 정도를 검증","position":{"start":{"line":36,"column":3,"offset":696},"end":{"line":36,"column":61,"offset":754},"indent":[]}}],"position":{"start":{"line":36,"column":3,"offset":696},"end":{"line":36,"column":61,"offset":754},"indent":[]}}],"position":{"start":{"line":36,"column":1,"offset":694},"end":{"line":36,"column":61,"offset":754},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"얼마나 회귀선 주위에 몰려있는가","position":{"start":{"line":37,"column":3,"offset":757},"end":{"line":37,"column":20,"offset":774},"indent":[]}}],"position":{"start":{"line":37,"column":3,"offset":757},"end":{"line":37,"column":20,"offset":774},"indent":[]}}],"position":{"start":{"line":37,"column":1,"offset":755},"end":{"line":37,"column":20,"offset":774},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"적합도를 검증하는 방법은 \"추정의 표준오차\"와 \"결정계수\"를 구하는 방법","position":{"start":{"line":38,"column":3,"offset":777},"end":{"line":38,"column":43,"offset":817},"indent":[]}}],"position":{"start":{"line":38,"column":3,"offset":777},"end":{"line":38,"column":43,"offset":817},"indent":[]}}],"position":{"start":{"line":38,"column":1,"offset":775},"end":{"line":38,"column":43,"offset":817},"indent":[]}}],"position":{"start":{"line":36,"column":1,"offset":694},"end":{"line":38,"column":43,"offset":817},"indent":[1,1]}},{"type":"heading","depth":4,"children":[{"type":"text","value":"총변동","position":{"start":{"line":40,"column":6,"offset":824},"end":{"line":40,"column":9,"offset":827},"indent":[]}}],"position":{"start":{"line":40,"column":1,"offset":819},"end":{"line":40,"column":9,"offset":827},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"SST = SSR + SSE","position":{"start":{"line":42,"column":1,"offset":829},"end":{"line":42,"column":16,"offset":844},"indent":[]}}],"position":{"start":{"line":42,"column":1,"offset":829},"end":{"line":42,"column":16,"offset":844},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"SST : 총제곱합. 실제 값 y들이 이들의 평균y로부터 흩어진 정도","position":{"start":{"line":44,"column":3,"offset":848},"end":{"line":44,"column":41,"offset":886},"indent":[]}}],"position":{"start":{"line":44,"column":3,"offset":848},"end":{"line":44,"column":41,"offset":886},"indent":[]}}],"position":{"start":{"line":44,"column":1,"offset":846},"end":{"line":44,"column":41,"offset":886},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"SSR : 회귀제곱합. 예측치와 실제 값y들의 평균 y의 차이의 제곱의 합","position":{"start":{"line":45,"column":3,"offset":889},"end":{"line":45,"column":44,"offset":930},"indent":[]}}],"position":{"start":{"line":45,"column":3,"offset":889},"end":{"line":45,"column":44,"offset":930},"indent":[]}}],"position":{"start":{"line":45,"column":1,"offset":887},"end":{"line":45,"column":44,"offset":930},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"SSE : 오차제곱합. 예측치와 실체값의 차이의 제곱의 합","position":{"start":{"line":46,"column":3,"offset":933},"end":{"line":46,"column":35,"offset":965},"indent":[]}}],"position":{"start":{"line":46,"column":3,"offset":933},"end":{"line":46,"column":35,"offset":965},"indent":[]}}],"position":{"start":{"line":46,"column":1,"offset":931},"end":{"line":46,"column":35,"offset":965},"indent":[]}}],"position":{"start":{"line":44,"column":1,"offset":846},"end":{"line":46,"column":35,"offset":965},"indent":[1,1]}},{"type":"heading","depth":4,"children":[{"type":"text","value":"결정계수","position":{"start":{"line":48,"column":6,"offset":972},"end":{"line":48,"column":10,"offset":976},"indent":[]}}],"position":{"start":{"line":48,"column":1,"offset":967},"end":{"line":48,"column":10,"offset":976},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"$R^2 = \\frac{SSR}{SST} = 1 - \\frac{SSE}{SST}$","position":{"start":{"line":50,"column":1,"offset":978},"end":{"line":50,"column":46,"offset":1023},"indent":[]}}],"position":{"start":{"line":50,"column":1,"offset":978},"end":{"line":50,"column":46,"offset":1023},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"결정계수가 1에 가까울수록 정확성이 높음","position":{"start":{"line":52,"column":1,"offset":1025},"end":{"line":52,"column":23,"offset":1047},"indent":[]}}],"position":{"start":{"line":52,"column":1,"offset":1025},"end":{"line":52,"column":23,"offset":1047},"indent":[]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"성능평가","position":{"start":{"line":54,"column":5,"offset":1053},"end":{"line":54,"column":9,"offset":1057},"indent":[]}}],"position":{"start":{"line":54,"column":1,"offset":1049},"end":{"line":54,"column":9,"offset":1057},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"잔차 : 회귀분석 모델의 예측값과 실제값 사이 차이","position":{"start":{"line":56,"column":3,"offset":1061},"end":{"line":56,"column":31,"offset":1089},"indent":[]}}],"position":{"start":{"line":56,"column":3,"offset":1061},"end":{"line":56,"column":31,"offset":1089},"indent":[]}}],"position":{"start":{"line":56,"column":1,"offset":1059},"end":{"line":56,"column":31,"offset":1089},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"MSE(Mean Squared Error) : 평균제곱오차","position":{"start":{"line":57,"column":3,"offset":1092},"end":{"line":57,"column":35,"offset":1124},"indent":[]}}],"position":{"start":{"line":57,"column":3,"offset":1092},"end":{"line":57,"column":35,"offset":1124},"indent":[]}}],"position":{"start":{"line":57,"column":1,"offset":1090},"end":{"line":57,"column":35,"offset":1124},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"RMSE : 평균제곱근오차","position":{"start":{"line":58,"column":3,"offset":1127},"end":{"line":58,"column":17,"offset":1141},"indent":[]}}],"position":{"start":{"line":58,"column":3,"offset":1127},"end":{"line":58,"column":17,"offset":1141},"indent":[]}}],"position":{"start":{"line":58,"column":1,"offset":1125},"end":{"line":58,"column":17,"offset":1141},"indent":[]}}],"position":{"start":{"line":56,"column":1,"offset":1059},"end":{"line":58,"column":17,"offset":1141},"indent":[1,1]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"다중선형회귀분석","position":{"start":{"line":60,"column":4,"offset":1146},"end":{"line":60,"column":12,"offset":1154},"indent":[]}}],"position":{"start":{"line":60,"column":1,"offset":1143},"end":{"line":60,"column":12,"offset":1154},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"2개 이상의 독립변수와 하나의 종속변수의 관계를 분석하는 방법","position":{"start":{"line":62,"column":3,"offset":1158},"end":{"line":62,"column":37,"offset":1192},"indent":[]}}],"position":{"start":{"line":62,"column":3,"offset":1158},"end":{"line":62,"column":37,"offset":1192},"indent":[]}}],"position":{"start":{"line":62,"column":1,"offset":1156},"end":{"line":62,"column":37,"offset":1192},"indent":[]}}],"position":{"start":{"line":62,"column":1,"offset":1156},"end":{"line":62,"column":37,"offset":1192},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"$$y = \\alpha + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + ... + + \\beta_k x_k + e$$","position":{"start":{"line":64,"column":1,"offset":1194},"end":{"line":64,"column":83,"offset":1276},"indent":[]}}],"position":{"start":{"line":64,"column":1,"offset":1194},"end":{"line":64,"column":83,"offset":1276},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"from sklearn import datasets\nboston_house_prices = datasets.load_boston()\nprint(boston_house_prices.keys())\nprint(boston_house_prices.data.shape)\nprint(boston_house_prices.feature_names)","position":{"start":{"line":67,"column":1,"offset":1279},"end":{"line":73,"column":4,"offset":1479},"indent":[1,1,1,1,1,1]}},{"type":"code","lang":null,"meta":null,"value":"dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])\n(506, 13)\n['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n 'B' 'LSTAT']","position":{"start":{"line":75,"column":1,"offset":1481},"end":{"line":78,"column":18,"offset":1661},"indent":[1,1,1]}},{"type":"code","lang":"python","meta":null,"value":"print(boston_house_prices.DESCR)","position":{"start":{"line":82,"column":1,"offset":1665},"end":{"line":84,"column":4,"offset":1711},"indent":[1,1]}},{"type":"code","lang":null,"meta":null,"value":".. _boston_dataset:\n\nBoston house prices dataset\n---------------------------\n\n**Data Set Characteristics:**\n\n    :Number of Instances: 506 \n\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n\n    :Attribute Information (in order):\n        - CRIM     per capita crime rate by town\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n        - INDUS    proportion of non-retail business acres per town\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n        - NOX      nitric oxides concentration (parts per 10 million)\n        - RM       average number of rooms per dwelling\n        - AGE      proportion of owner-occupied units built prior to 1940\n        - DIS      weighted distances to five Boston employment centres\n        - RAD      index of accessibility to radial highways\n        - TAX      full-value property-tax rate per $10,000\n        - PTRATIO  pupil-teacher ratio by town\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n        - LSTAT    % lower status of the population\n        - MEDV     Median value of owner-occupied homes in $1000's\n\n    :Missing Attribute Values: None\n\n    :Creator: Harrison, D. and Rubinfeld, D.L.\n\nThis is a copy of UCI ML housing dataset.\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n\n\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\nprices and the demand for clean air', J. Environ. Economics & Management,\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\npages 244-261 of the latter.\n\nThe Boston house-price data has been used in many machine learning papers that address regression\nproblems.   \n     \n.. topic:: References\n\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.","position":{"start":{"line":86,"column":1,"offset":1713},"end":{"line":136,"column":5,"offset":4256},"indent":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"데이터프레임으로 정제","position":{"start":{"line":139,"column":5,"offset":4263},"end":{"line":139,"column":16,"offset":4274},"indent":[]}}],"position":{"start":{"line":139,"column":1,"offset":4259},"end":{"line":139,"column":16,"offset":4274},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"data_frame = pd.DataFrame(boston_house_prices.data)\ndata_frame.tail()","position":{"start":{"line":142,"column":1,"offset":4277},"end":{"line":145,"column":4,"offset":4360},"indent":[1,1,1]}},{"type":"code","lang":"python","meta":null,"value":"data_frame.columns = boston_house_prices.feature_names\ndata_frame['Price'] = boston_house_prices.target\ndata_frame.tail()","position":{"start":{"line":150,"column":1,"offset":4365},"end":{"line":154,"column":4,"offset":4500},"indent":[1,1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"산점도 표현","position":{"start":{"line":159,"column":5,"offset":4509},"end":{"line":159,"column":11,"offset":4515},"indent":[]}}],"position":{"start":{"line":159,"column":1,"offset":4505},"end":{"line":159,"column":11,"offset":4515},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"data_frame.plot(kind=\"scatter\",x=\"RM\",y=\"Price\",figsize=(6,6),color='black', xlim=(4,8), ylim=(10,45))","position":{"start":{"line":162,"column":1,"offset":4518},"end":{"line":164,"column":4,"offset":4634},"indent":[1,1]}},{"type":"code","lang":null,"meta":null,"value":"<matplotlib.axes._subplots.AxesSubplot at 0x11f4fea00>","position":{"start":{"line":169,"column":1,"offset":4639},"end":{"line":169,"column":59,"offset":4697},"indent":[]}},{"type":"paragraph","children":[{"type":"image","title":null,"url":"ch3_simplelinearModel_files/ch3_simplelinearModel_25_1.png","alt":"png","position":{"start":{"line":174,"column":1,"offset":4702},"end":{"line":174,"column":67,"offset":4768},"indent":[]}}],"position":{"start":{"line":174,"column":1,"offset":4702},"end":{"line":174,"column":67,"offset":4768},"indent":[]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"데이터 훈련","position":{"start":{"line":177,"column":5,"offset":4775},"end":{"line":177,"column":11,"offset":4781},"indent":[]}}],"position":{"start":{"line":177,"column":1,"offset":4771},"end":{"line":177,"column":11,"offset":4781},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"linear_regression = linear_model.LinearRegression()\nlinear_regression.fit(X=pd.DataFrame(data_frame[\"RM\"]),y=data_frame[\"Price\"])\nprediction = linear_regression.predict(X=pd.DataFrame(data_frame[\"RM\"]))\nprint(\"a value = \", linear_regression.intercept_)\nprint(\"b value = \",linear_regression.coef_)","position":{"start":{"line":180,"column":1,"offset":4784},"end":{"line":186,"column":4,"offset":5094},"indent":[1,1,1,1,1,1]}},{"type":"code","lang":null,"meta":null,"value":"a value =  -34.67062077643857\nb value =  [9.10210898]","position":{"start":{"line":188,"column":1,"offset":5096},"end":{"line":189,"column":28,"offset":5157},"indent":[1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"적합도 검증","position":{"start":{"line":192,"column":5,"offset":5164},"end":{"line":192,"column":11,"offset":5170},"indent":[]}}],"position":{"start":{"line":192,"column":1,"offset":5160},"end":{"line":192,"column":11,"offset":5170},"indent":[]}},{"type":"heading","depth":5,"children":[{"type":"text","value":"잔차","position":{"start":{"line":193,"column":7,"offset":5177},"end":{"line":193,"column":9,"offset":5179},"indent":[]}}],"position":{"start":{"line":193,"column":1,"offset":5171},"end":{"line":193,"column":9,"offset":5179},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"residuals = data_frame[\"Price\"] - prediction\nresiduals.describe()","position":{"start":{"line":196,"column":1,"offset":5182},"end":{"line":199,"column":4,"offset":5261},"indent":[1,1,1]}},{"type":"code","lang":null,"meta":null,"value":"count    5.060000e+02\nmean     1.899227e-15\nstd      6.609606e+00\nmin     -2.334590e+01\n25%     -2.547477e+00\n50%      8.976267e-02\n75%      2.985532e+00\nmax      3.943314e+01\nName: Price, dtype: float64","position":{"start":{"line":204,"column":1,"offset":5266},"end":{"line":212,"column":32,"offset":5505},"indent":[1,1,1,1,1,1,1,1]}},{"type":"heading","depth":5,"children":[{"type":"text","value":"결정계수","position":{"start":{"line":216,"column":7,"offset":5515},"end":{"line":216,"column":11,"offset":5519},"indent":[]}}],"position":{"start":{"line":216,"column":1,"offset":5509},"end":{"line":216,"column":11,"offset":5519},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"SSE = (residuals**2).sum()\nSST = ((data_frame[\"Price\"]-data_frame[\"Price\"].mean())**2).sum()\nR_squared = 1 - (SSE/SST)\nprint(\"R_squared = \", R_squared)","position":{"start":{"line":219,"column":1,"offset":5522},"end":{"line":224,"column":4,"offset":5687},"indent":[1,1,1,1,1]}},{"type":"code","lang":null,"meta":null,"value":"R_squared =  0.4835254559913341","position":{"start":{"line":226,"column":1,"offset":5689},"end":{"line":226,"column":36,"offset":5724},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"data_frame.plot(kind=\"scatter\",x=5,y=\"Price\",figsize=(6,6),color=\"black\",xlim=(4,8),ylim=(10,45))\n\nplt.plot(data_frame[\"RM\"],prediction,color=\"blue\")","position":{"start":{"line":230,"column":1,"offset":5728},"end":{"line":234,"column":4,"offset":5891},"indent":[1,1,1,1]}},{"type":"code","lang":null,"meta":null,"value":"[<matplotlib.lines.Line2D at 0x11f75cfa0>]","position":{"start":{"line":239,"column":1,"offset":5896},"end":{"line":239,"column":47,"offset":5942},"indent":[]}},{"type":"paragraph","children":[{"type":"image","title":null,"url":"ch3_simplelinearModel_files/ch3_simplelinearModel_32_1.png","alt":"png","position":{"start":{"line":244,"column":1,"offset":5947},"end":{"line":244,"column":67,"offset":6013},"indent":[]}}],"position":{"start":{"line":244,"column":1,"offset":5947},"end":{"line":244,"column":67,"offset":6013},"indent":[]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"성능평가","position":{"start":{"line":247,"column":5,"offset":6020},"end":{"line":247,"column":9,"offset":6024},"indent":[]}}],"position":{"start":{"line":247,"column":1,"offset":6016},"end":{"line":247,"column":9,"offset":6024},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"print('score = ',linear_regression.score(X=pd.DataFrame(data_frame[5]),y=data_frame['Price']))\nprint('Mean_Squared_Error = ',mean_squared_error(prediction, data_frame['Price']))\nprint('RMSE = ',mean_squared_error(prediction, data_frame['Price'])**0.5)","position":{"start":{"line":250,"column":1,"offset":6027},"end":{"line":254,"column":4,"offset":6292},"indent":[1,1,1,1]}},{"type":"code","lang":null,"meta":null,"value":"score =  0.48352545599133423\nMean_Squared_Error =  43.60055177116956\nRMSE =  6.603071389222561","position":{"start":{"line":256,"column":1,"offset":6294},"end":{"line":258,"column":30,"offset":6400},"indent":[1,1]}},{"type":"code","lang":"python","meta":null,"value":"","position":{"start":{"line":262,"column":1,"offset":6404},"end":{"line":264,"column":4,"offset":6418},"indent":[1,1]}},{"type":"export","value":"export const _frontmatter = {\"title\":\"<파이썬을 이용한 빅데이터 분석> ch3\",\"date\":\"2020-08-06T00:00:00.000Z\",\"tags\":[\"Python\",\"BigData\",\"MachineLearning\"]}","position":{"start":{"line":266,"column":1,"offset":6420},"end":{"line":266,"column":143,"offset":6562},"indent":[]}}],"position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":266,"column":143,"offset":6562}}},"scopeImports":["import * as React from 'react'"],"scopeIdentifiers":["React"],"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"<파이썬을 이용한 빅데이터 분석> ch3\",\n  \"date\": \"2020-08-06T00:00:00.000Z\",\n  \"tags\": [\"Python\", \"BigData\", \"MachineLearning\"]\n};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component '\" + name + \"' was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"\\uD68C\\uADC0\\uBD84\\uC11D\\uC740 \\uC11C\\uB85C \\uC601\\uD5A5\\uC744 \\uC8FC\\uACE0\\uBC1B\\uC73C\\uBA74\\uC11C \\uC778\\uACFC\\uAD00\\uACC4\\uB97C \\uAC16\\uB294 \\uB3C5\\uB9BD\\uBCC0\\uC218\\uC640 \\uC885\\uC18D\\uBCC0\\uC218 \\uC0AC\\uC774\\uC758 \\uAD00\\uACC4\\uB97C \\uBD84\\uC11D\\uD558\\uB294\\uB370 \\uC0AC\\uC6A9\"), mdx(\"p\", null, \"\\uC885\\uC18D\\uBCC0\\uC218\\uC640 \\uB3C5\\uB9BD\\uBCC0\\uC218 \\uC0AC\\uC774\\uC758 \\uD568\\uC218\\uC801 \\uAD00\\uACC4\\uB97C \\uAE30\\uC220\\uD558\\uB294 \\uC218\\uD559\\uC801 \\uBC29\\uC815\\uC2DD\\uC744 \\uAD6C\\uD558\\uB294\\uB370 \\uC0AC\\uC6A9\"), mdx(\"h2\", null, \"\\uB2E8\\uC77C\\uC120\\uD615\\uD68C\\uADC0\\uBAA8\\uB378\"), mdx(\"p\", null, \"\\uC885\\uC18D\\uBCC0\\uC218 Y\\uAC00 \\uB3C5\\uB9BD\\uBCC0\\uC218 X\\uC640 \\uC624\\uCC28\\uD56D\\uC5D0 \\uC5B4\\uB5BB\\uAC8C \\uAD00\\uB828\\uB418\\uC5B4 \\uC788\\uB294\\uAC00\\uB97C \\uB098\\uD0C0\\uB0B4\\uB294 \\uBC29\\uC815\\uC2DD\"), mdx(\"p\", null, \"$$y = \\\\alpha + \\\\beta x + e$$\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Y : \\uC885\\uC18D\\uBCC0\\uC218\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\u0251 : X\\uAC12\\uC774 \\uBCC0\\uD574\\uB3C4 Y\\uC758 \\uBCC0\\uB3D9\\uC5D0\\uB294 \\uC601\\uD5A5\\uC744 \\uC8FC\\uC9C0 \\uC54A\\uB294 \\uD68C\\uADC0\\uACC4\\uC218\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\u03B2 : X\\uC758 \\uC601\\uD5A5\\uB825\\uC744 \\uD06C\\uAE30\\uC640 \\uBD80\\uD638\\uB85C \\uB098\\uD0C0\\uB0B4 \\uC8FC\\uB294 \\uD68C\\uADC0\\uACC4\\uC218, X\\uC758 \\uAE30\\uC6B8\\uAE30\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"X : \\uB3C5\\uB9BD\\uBCC0\\uC218\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\u025B : \\uC624\\uCC28\\uD56D. \\uB3C5\\uB9BD\\uBCC0\\uC218 X\\uC758 \\uAC12\\uC774 \\uC8FC\\uC5B4\\uC9C8 \\uB54C \\uC885\\uC18D\\uBCC0\\uC218 Y\\uC758 \\uC2E4\\uC81C\\uAC12\\uACFC \\uC608\\uCE21\\uAC12\\uC758 \\uCC28\\uC774\")), mdx(\"h3\", null, \"\\uD68C\\uADC0\\uACC4\\uC218 \\uCD94\\uC815\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uC218\\uC9D1\\uB41C \\uB370\\uC774\\uD130(\\uC0B0\\uD3EC\\uB3C4)\\uC5D0 \\uAC00\\uC7A5 \\uC801\\uC808\\uD55C \\uD68C\\uADC0\\uC9C1\\uC120\\uC744 \\uAD6C\\uD558\\uB294 \\uAC83\")), mdx(\"h3\", null, \"\\uCD5C\\uC18C\\uC790\\uC2B9\\uBC95\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uC794\\uCC28\\uB97C \\uC81C\\uACF1\\uD55C \\uAC12\\uB4E4\\uC758 \\uD569\\uC774 \\uCD5C\\uC18C\\uAC00 \\uB418\\uB3C4\\uB85D \\uD558\\uB294 \\uD45C\\uBCF8\\uD68C\\uADC0\\uC2DD\\uC758 \\uD68C\\uADC0\\uACC4\\uC218\\uB97C \\uAD6C\\uD558\\uB294 \\uBC29\\uBC95\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uC794\\uCC28 : X\\uAC00 \\uC8FC\\uC5B4\\uC9C8 \\uB54C \\uD45C\\uBCF8\\uD68C\\uADC0\\uC120\\uC758 \\uC608\\uCE21 \\uAC12\\uACFC \\uC2E4\\uC81C \\uAC12 \\uC0AC\\uC774\\uC758 \\uCC28\\uC774\")), mdx(\"p\", null, \"$$b = \\\\frac{n\\\\Sigma X_iY_i - \\\\Sigma X_i \\\\Sigma Y_i}{n\\\\Sigma (X_i)^2 - (\\\\Sigma X_i)^2} = \\\\frac{\\\\Sigma X_iY_i - n\\\\bar{X}\\\\bar{Y}}{\\\\Sigma (X_i)^2 - n(X_i)^2}$$\"), mdx(\"p\", null, \"$$a = \\\\bar{Y} - b\\\\bar{X}$$\"), mdx(\"h2\", null, \"\\uC801\\uD569\\uB3C4 \\uAC80\\uC99D\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uD45C\\uBCF8\\uC790\\uB8CC\\uB97C \\uC0AC\\uC6A9\\uD558\\uC5EC \\uAD6C\\uD55C \\uD45C\\uBCF8\\uD68C\\uADC0\\uC2DD\\uC774 \\uC885\\uC18D\\uBCC0\\uC218\\uC758 \\uAC12\\uC744 \\uC5B4\\uB290 \\uC815\\uB3C4 \\uC815\\uD655\\uD558\\uAC8C \\uC608\\uCE21\\uD560 \\uC218 \\uC788\\uB294\\uAC00\\uC758 \\uC815\\uB3C4\\uB97C \\uAC80\\uC99D\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uC5BC\\uB9C8\\uB098 \\uD68C\\uADC0\\uC120 \\uC8FC\\uC704\\uC5D0 \\uBAB0\\uB824\\uC788\\uB294\\uAC00\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uC801\\uD569\\uB3C4\\uB97C \\uAC80\\uC99D\\uD558\\uB294 \\uBC29\\uBC95\\uC740 \\\"\\uCD94\\uC815\\uC758 \\uD45C\\uC900\\uC624\\uCC28\\\"\\uC640 \\\"\\uACB0\\uC815\\uACC4\\uC218\\\"\\uB97C \\uAD6C\\uD558\\uB294 \\uBC29\\uBC95\")), mdx(\"h4\", null, \"\\uCD1D\\uBCC0\\uB3D9\"), mdx(\"p\", null, \"SST = SSR + SSE\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"SST : \\uCD1D\\uC81C\\uACF1\\uD569. \\uC2E4\\uC81C \\uAC12 y\\uB4E4\\uC774 \\uC774\\uB4E4\\uC758 \\uD3C9\\uADE0y\\uB85C\\uBD80\\uD130 \\uD769\\uC5B4\\uC9C4 \\uC815\\uB3C4\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"SSR : \\uD68C\\uADC0\\uC81C\\uACF1\\uD569. \\uC608\\uCE21\\uCE58\\uC640 \\uC2E4\\uC81C \\uAC12y\\uB4E4\\uC758 \\uD3C9\\uADE0 y\\uC758 \\uCC28\\uC774\\uC758 \\uC81C\\uACF1\\uC758 \\uD569\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"SSE : \\uC624\\uCC28\\uC81C\\uACF1\\uD569. \\uC608\\uCE21\\uCE58\\uC640 \\uC2E4\\uCCB4\\uAC12\\uC758 \\uCC28\\uC774\\uC758 \\uC81C\\uACF1\\uC758 \\uD569\")), mdx(\"h4\", null, \"\\uACB0\\uC815\\uACC4\\uC218\"), mdx(\"p\", null, \"$R^2 = \\\\frac{SSR}{SST} = 1 - \\\\frac{SSE}{SST}$\"), mdx(\"p\", null, \"\\uACB0\\uC815\\uACC4\\uC218\\uAC00 1\\uC5D0 \\uAC00\\uAE4C\\uC6B8\\uC218\\uB85D \\uC815\\uD655\\uC131\\uC774 \\uB192\\uC74C\"), mdx(\"h3\", null, \"\\uC131\\uB2A5\\uD3C9\\uAC00\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uC794\\uCC28 : \\uD68C\\uADC0\\uBD84\\uC11D \\uBAA8\\uB378\\uC758 \\uC608\\uCE21\\uAC12\\uACFC \\uC2E4\\uC81C\\uAC12 \\uC0AC\\uC774 \\uCC28\\uC774\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"MSE(Mean Squared Error) : \\uD3C9\\uADE0\\uC81C\\uACF1\\uC624\\uCC28\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"RMSE : \\uD3C9\\uADE0\\uC81C\\uACF1\\uADFC\\uC624\\uCC28\")), mdx(\"h2\", null, \"\\uB2E4\\uC911\\uC120\\uD615\\uD68C\\uADC0\\uBD84\\uC11D\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"2\\uAC1C \\uC774\\uC0C1\\uC758 \\uB3C5\\uB9BD\\uBCC0\\uC218\\uC640 \\uD558\\uB098\\uC758 \\uC885\\uC18D\\uBCC0\\uC218\\uC758 \\uAD00\\uACC4\\uB97C \\uBD84\\uC11D\\uD558\\uB294 \\uBC29\\uBC95\")), mdx(\"p\", null, \"$$y = \\\\alpha + \\\\beta_1 x_1 + \\\\beta_2 x_2 + \\\\beta_3 x_3 + ... + + \\\\beta_k x_k + e$$\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"from sklearn import datasets\\nboston_house_prices = datasets.load_boston()\\nprint(boston_house_prices.keys())\\nprint(boston_house_prices.data.shape)\\nprint(boston_house_prices.feature_names)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])\\n(506, 13)\\n['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\\n 'B' 'LSTAT']\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"print(boston_house_prices.DESCR)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\")), mdx(\"h3\", null, \"\\uB370\\uC774\\uD130\\uD504\\uB808\\uC784\\uC73C\\uB85C \\uC815\\uC81C\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"data_frame = pd.DataFrame(boston_house_prices.data)\\ndata_frame.tail()\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"data_frame.columns = boston_house_prices.feature_names\\ndata_frame['Price'] = boston_house_prices.target\\ndata_frame.tail()\\n\")), mdx(\"h3\", null, \"\\uC0B0\\uC810\\uB3C4 \\uD45C\\uD604\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"data_frame.plot(kind=\\\"scatter\\\",x=\\\"RM\\\",y=\\\"Price\\\",figsize=(6,6),color='black', xlim=(4,8), ylim=(10,45))\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"<matplotlib.axes._subplots.AxesSubplot at 0x11f4fea00>\\n\")), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"ch3_simplelinearModel_files/ch3_simplelinearModel_25_1.png\",\n    \"alt\": \"png\"\n  }))), mdx(\"h3\", null, \"\\uB370\\uC774\\uD130 \\uD6C8\\uB828\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"linear_regression = linear_model.LinearRegression()\\nlinear_regression.fit(X=pd.DataFrame(data_frame[\\\"RM\\\"]),y=data_frame[\\\"Price\\\"])\\nprediction = linear_regression.predict(X=pd.DataFrame(data_frame[\\\"RM\\\"]))\\nprint(\\\"a value = \\\", linear_regression.intercept_)\\nprint(\\\"b value = \\\",linear_regression.coef_)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"a value =  -34.67062077643857\\nb value =  [9.10210898]\\n\")), mdx(\"h3\", null, \"\\uC801\\uD569\\uB3C4 \\uAC80\\uC99D\"), mdx(\"h5\", null, \"\\uC794\\uCC28\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"residuals = data_frame[\\\"Price\\\"] - prediction\\nresiduals.describe()\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"count    5.060000e+02\\nmean     1.899227e-15\\nstd      6.609606e+00\\nmin     -2.334590e+01\\n25%     -2.547477e+00\\n50%      8.976267e-02\\n75%      2.985532e+00\\nmax      3.943314e+01\\nName: Price, dtype: float64\\n\")), mdx(\"h5\", null, \"\\uACB0\\uC815\\uACC4\\uC218\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"SSE = (residuals**2).sum()\\nSST = ((data_frame[\\\"Price\\\"]-data_frame[\\\"Price\\\"].mean())**2).sum()\\nR_squared = 1 - (SSE/SST)\\nprint(\\\"R_squared = \\\", R_squared)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"R_squared =  0.4835254559913341\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"data_frame.plot(kind=\\\"scatter\\\",x=5,y=\\\"Price\\\",figsize=(6,6),color=\\\"black\\\",xlim=(4,8),ylim=(10,45))\\n\\nplt.plot(data_frame[\\\"RM\\\"],prediction,color=\\\"blue\\\")\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"[<matplotlib.lines.Line2D at 0x11f75cfa0>]\\n\")), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"ch3_simplelinearModel_files/ch3_simplelinearModel_32_1.png\",\n    \"alt\": \"png\"\n  }))), mdx(\"h3\", null, \"\\uC131\\uB2A5\\uD3C9\\uAC00\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"print('score = ',linear_regression.score(X=pd.DataFrame(data_frame[5]),y=data_frame['Price']))\\nprint('Mean_Squared_Error = ',mean_squared_error(prediction, data_frame['Price']))\\nprint('RMSE = ',mean_squared_error(prediction, data_frame['Price'])**0.5)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"score =  0.48352545599133423\\nMean_Squared_Error =  43.60055177116956\\nRMSE =  6.603071389222561\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"\")));\n}\n;\nMDXContent.isMDXComponent = true;","rawMDXOutput":"/* @jsx mdx */\nimport { mdx } from '@mdx-js/react';\n/* @jsx mdx */\n\nexport const _frontmatter = {\n  \"title\": \"<파이썬을 이용한 빅데이터 분석> ch3\",\n  \"date\": \"2020-08-06T00:00:00.000Z\",\n  \"tags\": [\"Python\", \"BigData\", \"MachineLearning\"]\n};\nconst makeShortcode = name => function MDXDefaultShortcode(props) {\n  console.warn(\"Component '\" + name + \"' was not imported, exported, or provided by MDXProvider as global scope\")\n  return <div {...props}/>\n};\n\nconst layoutProps = {\n  _frontmatter\n};\nconst MDXLayout = \"wrapper\"\nexport default function MDXContent({\n  components,\n  ...props\n}) {\n  return <MDXLayout {...layoutProps} {...props} components={components} mdxType=\"MDXLayout\">\n    <p>{`회귀분석은 서로 영향을 주고받으면서 인과관계를 갖는 독립변수와 종속변수 사이의 관계를 분석하는데 사용`}</p>\n    <p>{`종속변수와 독립변수 사이의 함수적 관계를 기술하는 수학적 방정식을 구하는데 사용`}</p>\n    <h2>{`단일선형회귀모델`}</h2>\n    <p>{`종속변수 Y가 독립변수 X와 오차항에 어떻게 관련되어 있는가를 나타내는 방정식`}</p>\n    <p>{`$$y = \\\\alpha + \\\\beta x + e$$`}</p>\n    <ul>\n      <li parentName=\"ul\">{`Y : 종속변수`}</li>\n      <li parentName=\"ul\">{`ɑ : X값이 변해도 Y의 변동에는 영향을 주지 않는 회귀계수`}</li>\n      <li parentName=\"ul\">{`β : X의 영향력을 크기와 부호로 나타내 주는 회귀계수, X의 기울기`}</li>\n      <li parentName=\"ul\">{`X : 독립변수`}</li>\n      <li parentName=\"ul\">{`ɛ : 오차항. 독립변수 X의 값이 주어질 때 종속변수 Y의 실제값과 예측값의 차이`}</li>\n    </ul>\n    <h3>{`회귀계수 추정`}</h3>\n    <ul>\n      <li parentName=\"ul\">{`수집된 데이터(산포도)에 가장 적절한 회귀직선을 구하는 것`}</li>\n    </ul>\n    <h3>{`최소자승법`}</h3>\n    <ul>\n      <li parentName=\"ul\">{`잔차를 제곱한 값들의 합이 최소가 되도록 하는 표본회귀식의 회귀계수를 구하는 방법`}</li>\n      <li parentName=\"ul\">{`잔차 : X가 주어질 때 표본회귀선의 예측 값과 실제 값 사이의 차이`}</li>\n    </ul>\n    <p>{`$$b = \\\\frac{n\\\\Sigma X_iY_i - \\\\Sigma X_i \\\\Sigma Y_i}{n\\\\Sigma (X_i)^2 - (\\\\Sigma X_i)^2} = \\\\frac{\\\\Sigma X_iY_i - n\\\\bar{X}\\\\bar{Y}}{\\\\Sigma (X_i)^2 - n(X_i)^2}$$`}</p>\n    <p>{`$$a = \\\\bar{Y} - b\\\\bar{X}$$`}</p>\n    <h2>{`적합도 검증`}</h2>\n    <ul>\n      <li parentName=\"ul\">{`표본자료를 사용하여 구한 표본회귀식이 종속변수의 값을 어느 정도 정확하게 예측할 수 있는가의 정도를 검증`}</li>\n      <li parentName=\"ul\">{`얼마나 회귀선 주위에 몰려있는가`}</li>\n      <li parentName=\"ul\">{`적합도를 검증하는 방법은 \"추정의 표준오차\"와 \"결정계수\"를 구하는 방법`}</li>\n    </ul>\n    <h4>{`총변동`}</h4>\n    <p>{`SST = SSR + SSE`}</p>\n    <ul>\n      <li parentName=\"ul\">{`SST : 총제곱합. 실제 값 y들이 이들의 평균y로부터 흩어진 정도`}</li>\n      <li parentName=\"ul\">{`SSR : 회귀제곱합. 예측치와 실제 값y들의 평균 y의 차이의 제곱의 합`}</li>\n      <li parentName=\"ul\">{`SSE : 오차제곱합. 예측치와 실체값의 차이의 제곱의 합`}</li>\n    </ul>\n    <h4>{`결정계수`}</h4>\n    <p>{`$R^2 = \\\\frac{SSR}{SST} = 1 - \\\\frac{SSE}{SST}$`}</p>\n    <p>{`결정계수가 1에 가까울수록 정확성이 높음`}</p>\n    <h3>{`성능평가`}</h3>\n    <ul>\n      <li parentName=\"ul\">{`잔차 : 회귀분석 모델의 예측값과 실제값 사이 차이`}</li>\n      <li parentName=\"ul\">{`MSE(Mean Squared Error) : 평균제곱오차`}</li>\n      <li parentName=\"ul\">{`RMSE : 평균제곱근오차`}</li>\n    </ul>\n    <h2>{`다중선형회귀분석`}</h2>\n    <ul>\n      <li parentName=\"ul\">{`2개 이상의 독립변수와 하나의 종속변수의 관계를 분석하는 방법`}</li>\n    </ul>\n    <p>{`$$y = \\\\alpha + \\\\beta_1 x_1 + \\\\beta_2 x_2 + \\\\beta_3 x_3 + ... + + \\\\beta_k x_k + e$$`}</p>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`from sklearn import datasets\nboston_house_prices = datasets.load_boston()\nprint(boston_house_prices.keys())\nprint(boston_house_prices.data.shape)\nprint(boston_house_prices.feature_names)\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])\n(506, 13)\n['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n 'B' 'LSTAT']\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`print(boston_house_prices.DESCR)\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`.. _boston_dataset:\n\nBoston house prices dataset\n---------------------------\n\n**Data Set Characteristics:**\n\n    :Number of Instances: 506 \n\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n\n    :Attribute Information (in order):\n        - CRIM     per capita crime rate by town\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n        - INDUS    proportion of non-retail business acres per town\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n        - NOX      nitric oxides concentration (parts per 10 million)\n        - RM       average number of rooms per dwelling\n        - AGE      proportion of owner-occupied units built prior to 1940\n        - DIS      weighted distances to five Boston employment centres\n        - RAD      index of accessibility to radial highways\n        - TAX      full-value property-tax rate per $10,000\n        - PTRATIO  pupil-teacher ratio by town\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n        - LSTAT    % lower status of the population\n        - MEDV     Median value of owner-occupied homes in $1000's\n\n    :Missing Attribute Values: None\n\n    :Creator: Harrison, D. and Rubinfeld, D.L.\n\nThis is a copy of UCI ML housing dataset.\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n\n\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\nprices and the demand for clean air', J. Environ. Economics & Management,\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\npages 244-261 of the latter.\n\nThe Boston house-price data has been used in many machine learning papers that address regression\nproblems.   \n     \n.. topic:: References\n\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n`}</code></pre>\n    <h3>{`데이터프레임으로 정제`}</h3>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`data_frame = pd.DataFrame(boston_house_prices.data)\ndata_frame.tail()\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`data_frame.columns = boston_house_prices.feature_names\ndata_frame['Price'] = boston_house_prices.target\ndata_frame.tail()\n`}</code></pre>\n    <h3>{`산점도 표현`}</h3>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`data_frame.plot(kind=\"scatter\",x=\"RM\",y=\"Price\",figsize=(6,6),color='black', xlim=(4,8), ylim=(10,45))\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`<matplotlib.axes._subplots.AxesSubplot at 0x11f4fea00>\n`}</code></pre>\n    <p><img parentName=\"p\" {...{\n        \"src\": \"ch3_simplelinearModel_files/ch3_simplelinearModel_25_1.png\",\n        \"alt\": \"png\"\n      }}></img></p>\n    <h3>{`데이터 훈련`}</h3>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`linear_regression = linear_model.LinearRegression()\nlinear_regression.fit(X=pd.DataFrame(data_frame[\"RM\"]),y=data_frame[\"Price\"])\nprediction = linear_regression.predict(X=pd.DataFrame(data_frame[\"RM\"]))\nprint(\"a value = \", linear_regression.intercept_)\nprint(\"b value = \",linear_regression.coef_)\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`a value =  -34.67062077643857\nb value =  [9.10210898]\n`}</code></pre>\n    <h3>{`적합도 검증`}</h3>\n    <h5>{`잔차`}</h5>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`residuals = data_frame[\"Price\"] - prediction\nresiduals.describe()\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`count    5.060000e+02\nmean     1.899227e-15\nstd      6.609606e+00\nmin     -2.334590e+01\n25%     -2.547477e+00\n50%      8.976267e-02\n75%      2.985532e+00\nmax      3.943314e+01\nName: Price, dtype: float64\n`}</code></pre>\n    <h5>{`결정계수`}</h5>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`SSE = (residuals**2).sum()\nSST = ((data_frame[\"Price\"]-data_frame[\"Price\"].mean())**2).sum()\nR_squared = 1 - (SSE/SST)\nprint(\"R_squared = \", R_squared)\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`R_squared =  0.4835254559913341\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`data_frame.plot(kind=\"scatter\",x=5,y=\"Price\",figsize=(6,6),color=\"black\",xlim=(4,8),ylim=(10,45))\n\nplt.plot(data_frame[\"RM\"],prediction,color=\"blue\")\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`[<matplotlib.lines.Line2D at 0x11f75cfa0>]\n`}</code></pre>\n    <p><img parentName=\"p\" {...{\n        \"src\": \"ch3_simplelinearModel_files/ch3_simplelinearModel_32_1.png\",\n        \"alt\": \"png\"\n      }}></img></p>\n    <h3>{`성능평가`}</h3>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`print('score = ',linear_regression.score(X=pd.DataFrame(data_frame[5]),y=data_frame['Price']))\nprint('Mean_Squared_Error = ',mean_squared_error(prediction, data_frame['Price']))\nprint('RMSE = ',mean_squared_error(prediction, data_frame['Price'])**0.5)\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`score =  0.48352545599133423\nMean_Squared_Error =  43.60055177116956\nRMSE =  6.603071389222561\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{``}</code></pre>\n\n    </MDXLayout>;\n}\n\n;\nMDXContent.isMDXComponent = true;"}}