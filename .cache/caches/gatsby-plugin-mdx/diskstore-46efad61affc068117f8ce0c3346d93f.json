{"expireTime":9007200852000205000,"key":"gatsby-plugin-mdx-entire-payload-b3c8ca0ec7f07390ab44e16d46cb7f0c-","val":{"mdast":{"type":"root","children":[{"type":"heading","depth":2,"children":[{"type":"text","value":"Scikit learn 제공 Toy Data 사용한 실습","position":{"start":{"line":2,"column":4,"offset":4},"end":{"line":2,"column":35,"offset":35},"indent":[]}}],"position":{"start":{"line":2,"column":1,"offset":1},"end":{"line":2,"column":35,"offset":35},"indent":[]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"데이터 셋과 의사결정 트리 기반 분류기 관련 클래스 불러오기","position":{"start":{"line":4,"column":5,"offset":41},"end":{"line":4,"column":38,"offset":74},"indent":[]}}],"position":{"start":{"line":4,"column":1,"offset":37},"end":{"line":4,"column":38,"offset":74},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"from sklearn import datasets\nfrom sklearn.tree import DecisionTreeClassifier","position":{"start":{"line":7,"column":1,"offset":77},"end":{"line":10,"column":4,"offset":167},"indent":[1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"데이터셋 분리 모듈 불러오기","position":{"start":{"line":12,"column":5,"offset":173},"end":{"line":12,"column":20,"offset":188},"indent":[]}}],"position":{"start":{"line":12,"column":1,"offset":169},"end":{"line":12,"column":20,"offset":188},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score","position":{"start":{"line":15,"column":1,"offset":191},"end":{"line":19,"column":4,"offset":361},"indent":[1,1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"성능평가 모듈 불러오기","position":{"start":{"line":21,"column":5,"offset":367},"end":{"line":21,"column":17,"offset":379},"indent":[]}}],"position":{"start":{"line":21,"column":1,"offset":363},"end":{"line":21,"column":17,"offset":379},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import mean_squared_error","position":{"start":{"line":24,"column":1,"offset":382},"end":{"line":30,"column":4,"offset":622},"indent":[1,1,1,1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"데이터 셋 구성","position":{"start":{"line":32,"column":5,"offset":628},"end":{"line":32,"column":13,"offset":636},"indent":[]}}],"position":{"start":{"line":32,"column":1,"offset":624},"end":{"line":32,"column":13,"offset":636},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"data = datasets.load_breast_cancer()\nX = data.data\ny = data.target","position":{"start":{"line":35,"column":1,"offset":639},"end":{"line":39,"column":4,"offset":719},"indent":[1,1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Holdout","position":{"start":{"line":41,"column":5,"offset":725},"end":{"line":41,"column":12,"offset":732},"indent":[]}}],"position":{"start":{"line":41,"column":1,"offset":721},"end":{"line":41,"column":12,"offset":732},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)","position":{"start":{"line":44,"column":1,"offset":735},"end":{"line":46,"column":4,"offset":819},"indent":[1,1]}},{"type":"paragraph","children":[{"type":"text","value":"데이터 셋을 8:2의 비율로 훈련셋과 테스트셋으로 분리한다.","position":{"start":{"line":48,"column":1,"offset":821},"end":{"line":48,"column":34,"offset":854},"indent":[]}}],"position":{"start":{"line":48,"column":1,"offset":821},"end":{"line":48,"column":34,"offset":854},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"clf = DecisionTreeClassifier()\nclf.fit(X_train,y_train)\nclf","position":{"start":{"line":51,"column":1,"offset":857},"end":{"line":55,"column":4,"offset":930},"indent":[1,1,1,1]}},{"type":"code","lang":null,"meta":null,"value":"DecisionTreeClassifier()","position":{"start":{"line":60,"column":1,"offset":935},"end":{"line":60,"column":29,"offset":963},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Decision Tree 분류 모델을 생성하여 fit함수를 통해 훈련시킨다.","position":{"start":{"line":64,"column":1,"offset":967},"end":{"line":64,"column":43,"offset":1009},"indent":[]}}],"position":{"start":{"line":64,"column":1,"offset":967},"end":{"line":64,"column":43,"offset":1009},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"y_pred = clf.predict(X_test)","position":{"start":{"line":67,"column":1,"offset":1012},"end":{"line":69,"column":4,"offset":1054},"indent":[1,1]}},{"type":"paragraph","children":[{"type":"text","value":"y_pred 변수에 X_test의 예측값을 저장한다","position":{"start":{"line":71,"column":1,"offset":1056},"end":{"line":71,"column":29,"offset":1084},"indent":[]}}],"position":{"start":{"line":71,"column":1,"offset":1056},"end":{"line":71,"column":29,"offset":1084},"indent":[]}},{"type":"heading","depth":4,"children":[{"type":"text","value":"모델 성능 평가","position":{"start":{"line":75,"column":6,"offset":1093},"end":{"line":75,"column":14,"offset":1101},"indent":[]}}],"position":{"start":{"line":75,"column":1,"offset":1088},"end":{"line":75,"column":14,"offset":1101},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"print(\"Confusion matrix\")\nprint(confusion_matrix(y_test,y_pred))","position":{"start":{"line":78,"column":1,"offset":1104},"end":{"line":81,"column":4,"offset":1182},"indent":[1,1,1]}},{"type":"code","lang":null,"meta":null,"value":"Confusion matrix\n[[40  2]\n [ 5 67]]","position":{"start":{"line":83,"column":1,"offset":1184},"end":{"line":85,"column":14,"offset":1231},"indent":[1,1]}},{"type":"code","lang":"python","meta":null,"value":"print(\"Accuracy\")\nprint(accuracy_score(y_test,y_pred,normalize=True))","position":{"start":{"line":89,"column":1,"offset":1235},"end":{"line":92,"column":4,"offset":1318},"indent":[1,1,1]}},{"type":"code","lang":null,"meta":null,"value":"Accuracy\n0.9385964912280702","position":{"start":{"line":94,"column":1,"offset":1320},"end":{"line":95,"column":23,"offset":1355},"indent":[1]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"normalize=True : 올바르게 분류된 데이터의 비율 출력","position":{"start":{"line":98,"column":3,"offset":1360},"end":{"line":98,"column":39,"offset":1396},"indent":[]}}],"position":{"start":{"line":98,"column":3,"offset":1360},"end":{"line":98,"column":39,"offset":1396},"indent":[]}}],"position":{"start":{"line":98,"column":1,"offset":1358},"end":{"line":98,"column":39,"offset":1396},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"normalize=False : 올바르게 분류된 데이터 건수 출력","position":{"start":{"line":99,"column":3,"offset":1399},"end":{"line":99,"column":39,"offset":1435},"indent":[]}}],"position":{"start":{"line":99,"column":3,"offset":1399},"end":{"line":99,"column":39,"offset":1435},"indent":[]}}],"position":{"start":{"line":99,"column":1,"offset":1397},"end":{"line":99,"column":39,"offset":1435},"indent":[]}}],"position":{"start":{"line":98,"column":1,"offset":1358},"end":{"line":99,"column":39,"offset":1435},"indent":[1]}},{"type":"code","lang":"python","meta":null,"value":"print(\"Classification Report\")\nprint(classification_report(y_test,y_pred))","position":{"start":{"line":102,"column":1,"offset":1438},"end":{"line":105,"column":4,"offset":1526},"indent":[1,1,1]}},{"type":"code","lang":null,"meta":null,"value":"Classification Report\n              precision    recall  f1-score   support\n\n           0       0.89      0.95      0.92        42\n           1       0.97      0.93      0.95        72\n\n    accuracy                           0.94       114\n   macro avg       0.93      0.94      0.93       114\nweighted avg       0.94      0.94      0.94       114","position":{"start":{"line":107,"column":1,"offset":1528},"end":{"line":116,"column":5,"offset":1916},"indent":[1,1,1,1,1,1,1,1,1]}},{"type":"code","lang":"python","meta":null,"value":"print(\"AUC\")\nprint(roc_auc_score(y_test,y_pred))","position":{"start":{"line":120,"column":1,"offset":1920},"end":{"line":123,"column":4,"offset":1982},"indent":[1,1,1]}},{"type":"code","lang":null,"meta":null,"value":"AUC\n0.941468253968254","position":{"start":{"line":125,"column":1,"offset":1984},"end":{"line":126,"column":22,"offset":2013},"indent":[1]}},{"type":"code","lang":"python","meta":null,"value":"print(\"Mean Squared Error\")\nprint(mean_squared_error(y_test,y_pred))","position":{"start":{"line":130,"column":1,"offset":2017},"end":{"line":133,"column":4,"offset":2099},"indent":[1,1,1]}},{"type":"code","lang":null,"meta":null,"value":"Mean Squared Error\n0.06140350877192982","position":{"start":{"line":135,"column":1,"offset":2101},"end":{"line":136,"column":24,"offset":2147},"indent":[1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"K fold Cross Validation","position":{"start":{"line":140,"column":5,"offset":2155},"end":{"line":140,"column":28,"offset":2178},"indent":[]}}],"position":{"start":{"line":140,"column":1,"offset":2151},"end":{"line":140,"column":28,"offset":2178},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"skf = StratifiedKFold(n_splits=10)\nskf.get_n_splits(X,y)\nprint(skf)","position":{"start":{"line":143,"column":1,"offset":2181},"end":{"line":147,"column":4,"offset":2262},"indent":[1,1,1,1]}},{"type":"code","lang":null,"meta":null,"value":"StratifiedKFold(n_splits=10, random_state=None, shuffle=False)","position":{"start":{"line":149,"column":1,"offset":2264},"end":{"line":149,"column":67,"offset":2330},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"10개의 폴드로 분리","position":{"start":{"line":152,"column":1,"offset":2333},"end":{"line":152,"column":12,"offset":2344},"indent":[]}}],"position":{"start":{"line":152,"column":1,"offset":2333},"end":{"line":152,"column":12,"offset":2344},"indent":[]}},{"type":"heading","depth":4,"children":[{"type":"text","value":"성능평가","position":{"start":{"line":154,"column":6,"offset":2351},"end":{"line":154,"column":10,"offset":2355},"indent":[]}}],"position":{"start":{"line":154,"column":1,"offset":2346},"end":{"line":154,"column":10,"offset":2355},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"clf = DecisionTreeClassifier()\nscore = cross_val_score(clf,X,y,cv=skf)\nprint('K fold cross validation score')\nprint(score)\nprint('Average Accuracy')\nprint(score.mean())","position":{"start":{"line":157,"column":1,"offset":2358},"end":{"line":164,"column":4,"offset":2540},"indent":[1,1,1,1,1,1,1]}},{"type":"code","lang":null,"meta":null,"value":"K fold cross validation score\n[0.9122807  0.89473684 0.9122807  0.87719298 0.96491228 0.89473684\n 0.87719298 0.94736842 0.92982456 0.94642857]\nAverage Accuracy\n0.9156954887218044","position":{"start":{"line":166,"column":1,"offset":2542},"end":{"line":170,"column":23,"offset":2740},"indent":[1,1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"K fold Cross Validation-shuffle","position":{"start":{"line":173,"column":5,"offset":2747},"end":{"line":173,"column":36,"offset":2778},"indent":[]}}],"position":{"start":{"line":173,"column":1,"offset":2743},"end":{"line":173,"column":36,"offset":2778},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"skf_sh = StratifiedKFold(n_splits=10,shuffle=True)\nskf_sh.get_n_splits(X,y)\nprint(skf_sh)","position":{"start":{"line":176,"column":1,"offset":2781},"end":{"line":180,"column":4,"offset":2884},"indent":[1,1,1,1]}},{"type":"code","lang":null,"meta":null,"value":"StratifiedKFold(n_splits=10, random_state=None, shuffle=True)","position":{"start":{"line":182,"column":1,"offset":2886},"end":{"line":182,"column":66,"offset":2951},"indent":[]}},{"type":"heading","depth":4,"children":[{"type":"text","value":"성능평가","position":{"start":{"line":185,"column":6,"offset":2959},"end":{"line":185,"column":10,"offset":2963},"indent":[]}}],"position":{"start":{"line":185,"column":1,"offset":2954},"end":{"line":185,"column":10,"offset":2963},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"clf = DecisionTreeClassifier()\nscore = cross_val_score(clf,X,y,cv=skf_sh)\nprint('K fold cross validation score')\nprint(score)\nprint('Average Accuracy')\nprint(score.mean())","position":{"start":{"line":188,"column":1,"offset":2966},"end":{"line":195,"column":4,"offset":3151},"indent":[1,1,1,1,1,1,1]}},{"type":"code","lang":null,"meta":null,"value":"K fold cross validation score\n[0.89473684 0.94736842 0.9122807  0.96491228 0.92982456 0.89473684\n 0.89473684 0.89473684 0.94736842 0.92857143]\nAverage Accuracy\n0.9209273182957393","position":{"start":{"line":197,"column":1,"offset":3153},"end":{"line":201,"column":23,"offset":3351},"indent":[1,1,1,1]}},{"type":"export","value":"export const _frontmatter = {\"title\":\"<파이썬을 이용한 빅데이터 분석> ch2 실습\",\"date\":\"2020-08-05T00:00:00.000Z\",\"tags\":[\"Python\",\"BigData\",\"MachineLearning\"]}","position":{"start":{"line":206,"column":1,"offset":3356},"end":{"line":206,"column":146,"offset":3501},"indent":[]}}],"position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":206,"column":146,"offset":3501}}},"scopeImports":["import * as React from 'react'"],"scopeIdentifiers":["React"],"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"<파이썬을 이용한 빅데이터 분석> ch2 실습\",\n  \"date\": \"2020-08-05T00:00:00.000Z\",\n  \"tags\": [\"Python\", \"BigData\", \"MachineLearning\"]\n};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component '\" + name + \"' was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h2\", null, \"Scikit learn \\uC81C\\uACF5 Toy Data \\uC0AC\\uC6A9\\uD55C \\uC2E4\\uC2B5\"), mdx(\"h3\", null, \"\\uB370\\uC774\\uD130 \\uC14B\\uACFC \\uC758\\uC0AC\\uACB0\\uC815 \\uD2B8\\uB9AC \\uAE30\\uBC18 \\uBD84\\uB958\\uAE30 \\uAD00\\uB828 \\uD074\\uB798\\uC2A4 \\uBD88\\uB7EC\\uC624\\uAE30\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"from sklearn import datasets\\nfrom sklearn.tree import DecisionTreeClassifier\\n\")), mdx(\"h3\", null, \"\\uB370\\uC774\\uD130\\uC14B \\uBD84\\uB9AC \\uBAA8\\uB4C8 \\uBD88\\uB7EC\\uC624\\uAE30\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"from sklearn.model_selection import train_test_split\\nfrom sklearn.model_selection import StratifiedKFold\\nfrom sklearn.model_selection import cross_val_score\\n\")), mdx(\"h3\", null, \"\\uC131\\uB2A5\\uD3C9\\uAC00 \\uBAA8\\uB4C8 \\uBD88\\uB7EC\\uC624\\uAE30\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"from sklearn.metrics import confusion_matrix\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.metrics import roc_auc_score\\nfrom sklearn.metrics import mean_squared_error\\n\")), mdx(\"h3\", null, \"\\uB370\\uC774\\uD130 \\uC14B \\uAD6C\\uC131\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"data = datasets.load_breast_cancer()\\nX = data.data\\ny = data.target\\n\")), mdx(\"h3\", null, \"Holdout\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\\n\")), mdx(\"p\", null, \"\\uB370\\uC774\\uD130 \\uC14B\\uC744 8:2\\uC758 \\uBE44\\uC728\\uB85C \\uD6C8\\uB828\\uC14B\\uACFC \\uD14C\\uC2A4\\uD2B8\\uC14B\\uC73C\\uB85C \\uBD84\\uB9AC\\uD55C\\uB2E4.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"clf = DecisionTreeClassifier()\\nclf.fit(X_train,y_train)\\nclf\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"DecisionTreeClassifier()\\n\")), mdx(\"p\", null, \"Decision Tree \\uBD84\\uB958 \\uBAA8\\uB378\\uC744 \\uC0DD\\uC131\\uD558\\uC5EC fit\\uD568\\uC218\\uB97C \\uD1B5\\uD574 \\uD6C8\\uB828\\uC2DC\\uD0A8\\uB2E4.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"y_pred = clf.predict(X_test)\\n\")), mdx(\"p\", null, \"y_pred \\uBCC0\\uC218\\uC5D0 X_test\\uC758 \\uC608\\uCE21\\uAC12\\uC744 \\uC800\\uC7A5\\uD55C\\uB2E4\"), mdx(\"h4\", null, \"\\uBAA8\\uB378 \\uC131\\uB2A5 \\uD3C9\\uAC00\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"print(\\\"Confusion matrix\\\")\\nprint(confusion_matrix(y_test,y_pred))\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"Confusion matrix\\n[[40  2]\\n [ 5 67]]\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"print(\\\"Accuracy\\\")\\nprint(accuracy_score(y_test,y_pred,normalize=True))\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"Accuracy\\n0.9385964912280702\\n\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"normalize=True : \\uC62C\\uBC14\\uB974\\uAC8C \\uBD84\\uB958\\uB41C \\uB370\\uC774\\uD130\\uC758 \\uBE44\\uC728 \\uCD9C\\uB825\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"normalize=False : \\uC62C\\uBC14\\uB974\\uAC8C \\uBD84\\uB958\\uB41C \\uB370\\uC774\\uD130 \\uAC74\\uC218 \\uCD9C\\uB825\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"print(\\\"Classification Report\\\")\\nprint(classification_report(y_test,y_pred))\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"Classification Report\\n              precision    recall  f1-score   support\\n\\n           0       0.89      0.95      0.92        42\\n           1       0.97      0.93      0.95        72\\n\\n    accuracy                           0.94       114\\n   macro avg       0.93      0.94      0.93       114\\nweighted avg       0.94      0.94      0.94       114\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"print(\\\"AUC\\\")\\nprint(roc_auc_score(y_test,y_pred))\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"AUC\\n0.941468253968254\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"print(\\\"Mean Squared Error\\\")\\nprint(mean_squared_error(y_test,y_pred))\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"Mean Squared Error\\n0.06140350877192982\\n\")), mdx(\"h3\", null, \"K fold Cross Validation\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"skf = StratifiedKFold(n_splits=10)\\nskf.get_n_splits(X,y)\\nprint(skf)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"StratifiedKFold(n_splits=10, random_state=None, shuffle=False)\\n\")), mdx(\"p\", null, \"10\\uAC1C\\uC758 \\uD3F4\\uB4DC\\uB85C \\uBD84\\uB9AC\"), mdx(\"h4\", null, \"\\uC131\\uB2A5\\uD3C9\\uAC00\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"clf = DecisionTreeClassifier()\\nscore = cross_val_score(clf,X,y,cv=skf)\\nprint('K fold cross validation score')\\nprint(score)\\nprint('Average Accuracy')\\nprint(score.mean())\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"K fold cross validation score\\n[0.9122807  0.89473684 0.9122807  0.87719298 0.96491228 0.89473684\\n 0.87719298 0.94736842 0.92982456 0.94642857]\\nAverage Accuracy\\n0.9156954887218044\\n\")), mdx(\"h3\", null, \"K fold Cross Validation-shuffle\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"skf_sh = StratifiedKFold(n_splits=10,shuffle=True)\\nskf_sh.get_n_splits(X,y)\\nprint(skf_sh)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"StratifiedKFold(n_splits=10, random_state=None, shuffle=True)\\n\")), mdx(\"h4\", null, \"\\uC131\\uB2A5\\uD3C9\\uAC00\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"clf = DecisionTreeClassifier()\\nscore = cross_val_score(clf,X,y,cv=skf_sh)\\nprint('K fold cross validation score')\\nprint(score)\\nprint('Average Accuracy')\\nprint(score.mean())\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"K fold cross validation score\\n[0.89473684 0.94736842 0.9122807  0.96491228 0.92982456 0.89473684\\n 0.89473684 0.89473684 0.94736842 0.92857143]\\nAverage Accuracy\\n0.9209273182957393\\n\")));\n}\n;\nMDXContent.isMDXComponent = true;","rawMDXOutput":"/* @jsx mdx */\nimport { mdx } from '@mdx-js/react';\n/* @jsx mdx */\n\nexport const _frontmatter = {\n  \"title\": \"<파이썬을 이용한 빅데이터 분석> ch2 실습\",\n  \"date\": \"2020-08-05T00:00:00.000Z\",\n  \"tags\": [\"Python\", \"BigData\", \"MachineLearning\"]\n};\nconst makeShortcode = name => function MDXDefaultShortcode(props) {\n  console.warn(\"Component '\" + name + \"' was not imported, exported, or provided by MDXProvider as global scope\")\n  return <div {...props}/>\n};\n\nconst layoutProps = {\n  _frontmatter\n};\nconst MDXLayout = \"wrapper\"\nexport default function MDXContent({\n  components,\n  ...props\n}) {\n  return <MDXLayout {...layoutProps} {...props} components={components} mdxType=\"MDXLayout\">\n    <h2>{`Scikit learn 제공 Toy Data 사용한 실습`}</h2>\n    <h3>{`데이터 셋과 의사결정 트리 기반 분류기 관련 클래스 불러오기`}</h3>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`from sklearn import datasets\nfrom sklearn.tree import DecisionTreeClassifier\n`}</code></pre>\n    <h3>{`데이터셋 분리 모듈 불러오기`}</h3>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\n`}</code></pre>\n    <h3>{`성능평가 모듈 불러오기`}</h3>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import mean_squared_error\n`}</code></pre>\n    <h3>{`데이터 셋 구성`}</h3>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`data = datasets.load_breast_cancer()\nX = data.data\ny = data.target\n`}</code></pre>\n    <h3>{`Holdout`}</h3>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n`}</code></pre>\n    <p>{`데이터 셋을 8:2의 비율로 훈련셋과 테스트셋으로 분리한다.`}</p>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`clf = DecisionTreeClassifier()\nclf.fit(X_train,y_train)\nclf\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`DecisionTreeClassifier()\n`}</code></pre>\n    <p>{`Decision Tree 분류 모델을 생성하여 fit함수를 통해 훈련시킨다.`}</p>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`y_pred = clf.predict(X_test)\n`}</code></pre>\n    <p>{`y_pred 변수에 X_test의 예측값을 저장한다`}</p>\n    <h4>{`모델 성능 평가`}</h4>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`print(\"Confusion matrix\")\nprint(confusion_matrix(y_test,y_pred))\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`Confusion matrix\n[[40  2]\n [ 5 67]]\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`print(\"Accuracy\")\nprint(accuracy_score(y_test,y_pred,normalize=True))\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`Accuracy\n0.9385964912280702\n`}</code></pre>\n    <ul>\n      <li parentName=\"ul\">{`normalize=True : 올바르게 분류된 데이터의 비율 출력`}</li>\n      <li parentName=\"ul\">{`normalize=False : 올바르게 분류된 데이터 건수 출력`}</li>\n    </ul>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`print(\"Classification Report\")\nprint(classification_report(y_test,y_pred))\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`Classification Report\n              precision    recall  f1-score   support\n\n           0       0.89      0.95      0.92        42\n           1       0.97      0.93      0.95        72\n\n    accuracy                           0.94       114\n   macro avg       0.93      0.94      0.93       114\nweighted avg       0.94      0.94      0.94       114\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`print(\"AUC\")\nprint(roc_auc_score(y_test,y_pred))\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`AUC\n0.941468253968254\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`print(\"Mean Squared Error\")\nprint(mean_squared_error(y_test,y_pred))\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`Mean Squared Error\n0.06140350877192982\n`}</code></pre>\n    <h3>{`K fold Cross Validation`}</h3>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`skf = StratifiedKFold(n_splits=10)\nskf.get_n_splits(X,y)\nprint(skf)\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`StratifiedKFold(n_splits=10, random_state=None, shuffle=False)\n`}</code></pre>\n    <p>{`10개의 폴드로 분리`}</p>\n    <h4>{`성능평가`}</h4>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`clf = DecisionTreeClassifier()\nscore = cross_val_score(clf,X,y,cv=skf)\nprint('K fold cross validation score')\nprint(score)\nprint('Average Accuracy')\nprint(score.mean())\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`K fold cross validation score\n[0.9122807  0.89473684 0.9122807  0.87719298 0.96491228 0.89473684\n 0.87719298 0.94736842 0.92982456 0.94642857]\nAverage Accuracy\n0.9156954887218044\n`}</code></pre>\n    <h3>{`K fold Cross Validation-shuffle`}</h3>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`skf_sh = StratifiedKFold(n_splits=10,shuffle=True)\nskf_sh.get_n_splits(X,y)\nprint(skf_sh)\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`StratifiedKFold(n_splits=10, random_state=None, shuffle=True)\n`}</code></pre>\n    <h4>{`성능평가`}</h4>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`clf = DecisionTreeClassifier()\nscore = cross_val_score(clf,X,y,cv=skf_sh)\nprint('K fold cross validation score')\nprint(score)\nprint('Average Accuracy')\nprint(score.mean())\n`}</code></pre>\n    <pre><code parentName=\"pre\" {...{}}>{`K fold cross validation score\n[0.89473684 0.94736842 0.9122807  0.96491228 0.92982456 0.89473684\n 0.89473684 0.89473684 0.94736842 0.92857143]\nAverage Accuracy\n0.9209273182957393\n`}</code></pre>\n\n    </MDXLayout>;\n}\n\n;\nMDXContent.isMDXComponent = true;"}}