---
title: <파이썬을 이용한 빅데이터 분석> ch2 실습
date: 2020-08-05
tags:
  - Python
  - BigData
  - MachineLearning
---

## Scikit learn 제공 Toy Data 사용한 실습

### 데이터 셋과 의사결정 트리 기반 분류기 관련 클래스 불러오기


```python
from sklearn import datasets
from sklearn.tree import DecisionTreeClassifier
```

### 데이터셋 분리 모듈 불러오기


```python
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import cross_val_score
```

### 성능평가 모듈 불러오기


```python
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
from sklearn.metrics import roc_auc_score
from sklearn.metrics import mean_squared_error
```

### 데이터 셋 구성


```python
data = datasets.load_breast_cancer()
X = data.data
y = data.target
```

### Holdout


```python
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)
```

데이터 셋을 8:2의 비율로 훈련셋과 테스트셋으로 분리한다.


```python
clf = DecisionTreeClassifier()
clf.fit(X_train,y_train)
clf
```




    DecisionTreeClassifier()



Decision Tree 분류 모델을 생성하여 fit함수를 통해 훈련시킨다.


```python
y_pred = clf.predict(X_test)
```

y_pred 변수에 X_test의 예측값을 저장한다



#### 모델 성능 평가


```python
print("Confusion matrix")
print(confusion_matrix(y_test,y_pred))
```

    Confusion matrix
    [[40  2]
     [ 5 67]]



```python
print("Accuracy")
print(accuracy_score(y_test,y_pred,normalize=True))
```

    Accuracy
    0.9385964912280702


- normalize=True : 올바르게 분류된 데이터의 비율 출력
- normalize=False : 올바르게 분류된 데이터 건수 출력


```python
print("Classification Report")
print(classification_report(y_test,y_pred))
```

    Classification Report
                  precision    recall  f1-score   support
    
               0       0.89      0.95      0.92        42
               1       0.97      0.93      0.95        72
    
        accuracy                           0.94       114
       macro avg       0.93      0.94      0.93       114
    weighted avg       0.94      0.94      0.94       114
    



```python
print("AUC")
print(roc_auc_score(y_test,y_pred))
```

    AUC
    0.941468253968254



```python
print("Mean Squared Error")
print(mean_squared_error(y_test,y_pred))
```

    Mean Squared Error
    0.06140350877192982



### K fold Cross Validation


```python
skf = StratifiedKFold(n_splits=10)
skf.get_n_splits(X,y)
print(skf)
```

    StratifiedKFold(n_splits=10, random_state=None, shuffle=False)


10개의 폴드로 분리

#### 성능평가


```python
clf = DecisionTreeClassifier()
score = cross_val_score(clf,X,y,cv=skf)
print('K fold cross validation score')
print(score)
print('Average Accuracy')
print(score.mean())
```

    K fold cross validation score
    [0.9122807  0.89473684 0.9122807  0.87719298 0.96491228 0.89473684
     0.87719298 0.94736842 0.92982456 0.94642857]
    Average Accuracy
    0.9156954887218044


### K fold Cross Validation-shuffle


```python
skf_sh = StratifiedKFold(n_splits=10,shuffle=True)
skf_sh.get_n_splits(X,y)
print(skf_sh)
```

    StratifiedKFold(n_splits=10, random_state=None, shuffle=True)


#### 성능평가


```python
clf = DecisionTreeClassifier()
score = cross_val_score(clf,X,y,cv=skf_sh)
print('K fold cross validation score')
print(score)
print('Average Accuracy')
print(score.mean())
```

    K fold cross validation score
    [0.89473684 0.94736842 0.9122807  0.96491228 0.92982456 0.89473684
     0.89473684 0.89473684 0.94736842 0.92857143]
    Average Accuracy
    0.9209273182957393


